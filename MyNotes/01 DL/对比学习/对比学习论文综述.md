---
tag: DL/Contrastive
alias: CV方向比较经典的对比学习论文，截止到2021年12月
---

学习来源：[对比学习论文综述【论文精读】_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV19S4y1M7hm/?spm_id_from=333.999.0.0&vd_source=acf9ba15a06b15485b18cecd879c6648)

## 百花齐放


## CV双雄

### MoCo
1. 改进简单有效并且有很大影响
	1. 动量编码器。在后续的SimCLR和BYOL等一直在使用
2. 写作方式 - 自顶向下
	1. 讲述了cv和nlp的区别，以及为什么cv的对比学习做的不好
	2. cv、nlp、对比学习框架统一的情况下，提出方法

### SimCLR
概念简单，容易理解。但是batchsize太大（4096/8192）

![image.png|400](https://s1.vika.cn/space/2023/03/14/9c118d249aab4236ae659621da00b9e1)
正样本：2    负样本：2(N-1)

增加mlp+relu可以在ImageNet上提升将近10个点。本篇论文在fc做非线性变换之后的特征是128维。

normalized  temperature-scaled 交叉熵函数

projection head函数 $g()$ 只有在训练的时候使用，下游任务只使用特征 h

相比较[[InvaSpread]]，贡献：
- 对比学习需要很强的数据增强技术
- 在编码器之后增加mlp层，可学习的非线性变换
- 使用lars优化器去做更大的batchsize并且训练时间更久。

数据增强策略：
![image.png](https://s1.vika.cn/space/2023/03/14/de7e484817434fe1bd0f6f7dcc2adb1b)
![image.png|500](https://s1.vika.cn/space/2023/03/14/3a1bd865c4b04c39a680157002b3c65e)
最有效的是==Crop==和==Color==


非线性层(mlp+relu)：
![image.png|500](https://s1.vika.cn/space/2023/03/14/82305b45debe49d6b84524cefdf4b99c)
- 维度大小没有影响，现在多数工作选择128维
- 至今没有理论能够证明有效性

### MoCo v2
将SimCLR上的技术用到MoCo上面。

改动：
1. 使用MLP层
2. 增加数据增强
3. 训练时候使用 cosine 的 learning rate schedule
4. 训练更长的epoch (200 -> 800)
![image.png|500](https://s1.vika.cn/space/2023/03/14/7d34433b6e1d42719f42157eabc02bca)

与SimCLR的比较：
![image.png|500](https://s1.vika.cn/space/2023/03/14/e9e819bf90044dfa9b7cb202aab81e26)

![image.png|500](https://s1.vika.cn/space/2023/03/14/0eb98f2891194eac8884d9a63d3d6773)

### SimCLR v2
小部分讲解模型改进从 v1 -> v2, 大部分篇幅讲如何做半监督学习

模型改进：
1. 更大的模型，无监督的对比学习效果会更好。152-layer ResNet，selective kernels(SK Net)
2. 加深protection head。fc-relu ---> fc-relu-fc-relu. 两层的FC效果更好
3. 使用 MoCo 提出的动量编码器。但是提升不多大概 ～1%。原因可能是原本的mini-batch已经很大，负样本足够多


SimCLR  v1 和 SimCLR v2 只做了分类任务。MoCo 做了很多下游任务



### SwAV
用一个视角的特征预测其他视角的特征，这些特征应该是相似的。对比学习 + 聚类

去跟聚类中心对比。ImageNet上大概有3000个聚类中心。

![image.png|700](https://s1.vika.cn/space/2023/03/14/f88b92eb10d14175841ded2776fae34f)

特征：(B, D)    prototypes：(D, K)

使用聚类：
1. 3000个聚类中心足够代表所有的负样本。即使MoCo的队列60000张图片也只是近似，不是和所有的负样本做对比。
2. 聚类中心含有明确语意信息。之前随机抽取样本可能还含有正样本。
了解聚类方法可参考一作的 deep cluster, deep cluster two


![image.png](https://s1.vika.cn/space/2023/03/14/19e0e9612dc74e33943796da845110da)

性能提升关键点：
1. 聚类
2. multi-crop：关注全局信息和局部信息


### 其他
cmc2: 适量互信息。infoMin，选择合适的数据增强等


## 不用负样本
### BYOL
负样本是一个约束。正样本是让同一类的物体特征尽可能相似。如果没有负样本则模型会学到一个shortcut：所有特征都一致



### SimSam
1. 不需要负样本
2. 不需要大batchsize
3. 不需要动量编码器

 ![image.png|500](https://s1.vika.cn/space/2023/03/15/821a3767cdc44254b6cf41b5e1d6ddf8)
stop-gradient操作。

Expectation-Maximization(EM) 操作


## Transformer

### MoCo v3




###