# 基于鲁棒学习的合成负数据密集异常检测

## 引言

标准的机器学习无法容纳不属于训练分布的输入。由此产生的模型往往会产生自信的错误预测，这可能会导致毁灭性的后果。这个问题在密集预测的背景下要求特别高，因为输入图像可能只是部分异常的。 以前的工作是通过对混合内容的图像进行判别性训练来解决密集的异常检测。我们用==合成负片==来扩展这种方法，它同时实现了高局内点的似然和平均分布的鉴别性预测。由于其出色的分布覆盖率和生成不同分辨率样本的能力，我们用==归一化流==生成合成负片。我们还提议根据一个==原则性的信息理论标准==来检测异常情况，该标准可以通过训练和推理来持续应用。尽管计算开销最小，而且不需要辅助的负面数据，但是由此产生的模型在标准基准和数据集上确立了新的技术水平。

## 1. 介绍

现代交通在过去十年中经历了巨大的进步。如今，绝大多数车辆都带有一定程度的驾驶辅助。该领域的进一步发展需要改善对自我载体周围环境的感知。一些相关的任务是场景解析[1]，重建[2]和语义预测[3]。场景理解的基本形式是将每个像素分类为$K$个预定义类中的一个，这对应于语义分割[1]。

近年来的语义分割方法[1,4]都是基于深度学习的。语义分割的深度模型将输入RGB image $x_{3×H×W}$ 映射到相应的预测 $y_{K×H×W}$，其中 $K$ 表示已知类的数量。通常，模型参数$θ$ 是通过基于最大似然的监督判别目标梯度优化得到的。最近的方法可以实时产生高保真的大图像分割，即使是在中等的GPU[4]上进行推断。然而，==标准学习容易对[5]的错误预测过于自信，这可能会使模型在存在域移位[6]时无法使用==。这对部署在现实世界中的深度模型构成了巨大威胁，特别是在自动驾驶领域。

我们研究用于自然图像理解的深度模型处理分布外输入的能力。我们希望在正确分割场景的同时，检测出与训练数据集中的任何景物都不一样的异常物体。稠密异常检测和标准稠密预测的整合导致了稠密开集识别。这种能力在道路驾驶场景中特别重要，因为对异常障碍物的错误检测可能导致严重的后果

以往的密集异常检测方法依赖于图像再合成[7,8,9]、贝叶斯建模[10,11]、潜在空间识别[12,13]或辅助负训练数据[14,15]。然而，所有这些方法都有明显的缺点。

- 图像再合成和贝叶斯方法需要大量的计算资源，但无法提供具有竞争力的性能。无论如何，这些方法都不适合实时应用。
- 由于依赖于预训练的分类器，潜在空间[12]的识别可能对特征崩溃很敏感[16,17]。
- 依赖辅助负数据可能会带来几种不希望出现的偏差，如对某些测试图像的表现过于乐观。此外，在某些应用领域可能无法获得适当的负数据。

这项工作通过鼓励一个标准的密集预测模型在异常值中发出统一的预测来解决密集异常检测问题[18]。我们建议在混合内容的图像上进行训练[15]，我们通过将合成的底片粘贴到异常点训练图像中来制作。合成底片的生成模型被联合训练，以生成产生均匀分布的判别预测的斑块，并在异常值中分配高可能性[18]。我们认为归一化流比GANs更适合手头的任务，因为它有**更好的分布覆盖和更稳定的训练**。此外，归一化流**可以产生不同空间维度的样本**[19]，这使得它们特别适合于模仿不同大小的异常物体。

本文对我们的初步报告[20]提出了两项主要改进。首先，我们表明==Jensen-Shannon散度==是训练和推理的首选标准。这比以前的方法更有原则性，这些方法优化了KL散度，并根据==Max-Softmax==进行推理[18, 14]。其次，我们提出了==两个阶段的训练==，以阻止判别模型对合成异常值的过度拟合。我们把这种综合方法称为NFlowJS。尽管放弃了辅助负面数据[15]，图像重新合成[8，7]和贝叶斯建模[10]，但是NFlowJS在密集异常检测的标准基准上仍然实现了最先进的性能。NFlowJS可以准确地检测到比以前最好的结果**大三倍的距离**的异常。最后，NFlowJS比标准判别模型的开销非常低，使其特别适合于**实时**应用。

## 2. 相关工作

有几个计算机视觉任务需要异常检测。在最简单的情况下，我们感兴趣的是给定的图像是内嵌的还是离群的\[21](第2.1节)。在实践中，这通常必须与主要识别任务[22]集成。由此产生的开集分类器对K个已知类和一个未知类的集合产生预测(第2.2节)。在密集预测的情况下，事情变得更加复杂，我们必须处理==内部场景中的离群对象==[15,12,8]\(第2.3节)。

异常检测的最简单的方法是看拟合于训练数据的生成模型所产生的可能性。然而，今天我们知道，这种方法既不简单也不直接[23]。不过，生成模型在非显式的异常检测方法中还是很有用的[18]。==生成流==在这种情况下特别有趣，因为它具有出色的分布覆盖率和生成不同分辨率样本的能力（2.4小节）。

> 这里我理解的生成模型在less obvious 方法中很有用的意思就是，不完全依赖生成模型去检测出异常，而是在这个过程中发挥辅助作用。比如生成负patch

### 2.1. 分布外检测

分布外(OOD)检测[21]是区分正常值和异常值的二分类任务。分布内样本，也称为内嵌样本，通过与训练数据相同的生成过程生成。相反，异常值由与训练分布[23]不相交的过程产生。OOD检测通常根据计分函数的 $S_δ$： $[0，1]^{3×H×W} → R$ 来执行，该计分函数为每个测试样本分配标量分数。我们通过对异常得分进行阈值来检测异常。

早期OOD检测器利用最大的softmax概率[21]。该评分函数可以利用抗对抗扰动[24]或辅助负数据[18]进一步改进。但是，前者需要额外处理，而后者可能不适用于任何大型图像数据集(例如:医学、天文和显微图像)中没有表示的非典型领域。此外，我们不能排除实验性能可能会因特定的负面数据集而产生偏差的疑问。

之前有几种方法可以用合成的方法来替代真实的底片[18,25]。一种开创性的方法[18]提出了生成对抗网络和标准分类器的合作训练。分类器损失要求在生成的样本中进行统一的预测，从而鼓励生成器在分布边界产生样本。这个想法可以在没有单独生成模型的情况下实现，通过利用Langevin采样[25]。然而，采用这些方法进行密集预测既不直接也不简单。

### 2.2. 开集识别

开放集识别集成了OOD检测和标准分类[22]。这些模型不鼓励对已知的K类进行过度泛化，从而试图将它们与开放世界的剩余视觉内容区分开来。许多方法通过抑制（reject）输入样本中被识别为异常值的已知类来实现这一目标[26,15,12,27]。

该任务和OOD检测的一个主要问题是，在特征空间[17]中，离群值和内层值可能无法区分。功能崩溃[16]可以通过强制模型学习更多的信息功能来缓解。这可以通过提供辅助的自我监督损失[17,28]来实现，也可以通过训练来自真实数据集[14,29,15]或从生成模型[18,20]中采样的负数据来实现。

### 2.3. 密度的开集识别

密度开集识别在改善道路驾驶场景的视觉感知方面有很大的潜力。最终的模型努力检测未知的危险，同时正确地分割现场的其他部分。

一个原则性贝叶斯方法密集异常检测测量认知不确定性[10]。然而，MC dropout对应于贝叶斯模型抽样的假设在实际中可能并不满足。异常也可以通过估计特征空间[12]的可能性来检测，但是这种方法容易受到特征崩溃[16]的影响。

辅助负数据密度开集识别训练的几种方法。这个想法需要两个实现细节[15]。

- 首先，将之前的负样例补丁粘贴到正训练示例中得到混合内容的图像进行训练。
- 第二，负面数据集应该尽可能广泛。(ImageNet, ADE20k或COCO)，以覆盖大部分的背景分布。这可能会将一些局内点的内部内容引入到负面图像中，但是产生的噪声可以通过仔细的批合成来缓解。

训练可以通过单独的OOD头[15]或通过最大化负像素[13]的softmax熵来实现。最近的研究表明，异常检测器也可以在辅助语义分割数据集[13]的实例类上进行训练。

另一项工作是用条件生成模型重新合成输入场景[7,8,30]。输入图像与重新合成图像之间的不同会产生竞争性的OOD检测。然而，再合成需要大量的计算开销，这限制了真实世界的应用。相关的方法[31]利用并行上采样路径进行输入重构。这提高了与生成再合成方法相比的推理速度，但不能正确地重建混乱的场景。

### 2.4. 生成的建模

生成式建模的主要目标是用一个统计模型来近似训练数据的隐式分布。早期的方法考虑了非标准化分布[32]，它需要基于MCMC样本生成的复杂训练过程。或者，分布可以被自回归分解为[33]，这允许似然估计和强大但缓慢的样本生成。由于采样速度慢，这两种方法都不适合生成合成底负片。

VAEs(变分自编码器)[34]使用因式变分近似，它允许学习似然的下界。然而，这种训练需要将编码器和解码器都存储在GPU内存中。这使得VAEs不适合密度预测模型联合训练，后者需要大量的批量和大量的作物[35]。正交上，GANs[36]忽略了可能性的因式分解。相反，生成网络通过在极大极小游戏中竞争来学习模仿数据集样本。然而，==所产生的样本不能跨越训练分布[37]的全部支持==，这使得gan不适合我们的任务。

与以前的方法相反，流归一化[19]通过对预定义的潜在分布p(z)的双目标映射来模拟似然，典型的是一个完全分解的高斯分布。给出一个异态 $f_{\gamma}$ ，根据变量变换公式定义似然：
$$
p_{\gamma} = p(z)|det\frac{\partial z}{\partial x}|,\quad z=f_{\gamma}(x) \tag{1}
$$
这种方法需要计算雅可比行列式(det $\frac{∂z}{∂x}$)。因此，==设计具有易处理的行列式计算和高效的逆运算的变换==是本文的重点。这种设置通过引入**跳跃连接**进一步改善，跳跃连接增加了容量并提高了收敛速度[38]。

训练后的归一化流 $f_γ$ 可分两步采样。首先,我们样本的分布来获得潜在的张量z。其次,通过逆变换我们恢复样本 $x=f^{−1}_γ(z)$ 。$f$ 是一个双射,==潜在的表示和生成的图像具有相同的维度==($R^{3×H×W}→[0,1]^{3×H×W}$)。这个属性对于生成合成底片特别有用，因为它允许在不同的分辨率[19]上训练和采样模型。

## 3. 使用NFlowJS进行密集异常检测

我们对混合内容图像[15]进行密集异常检测训练，该混合内容图像是通过将人工负片粘贴到常规训练图像中获得的。我们建议通过一个联合训练的规范化流来产生这样的负号(第3.1节)。我们根据一个原则性的信息理论标准(第3.2节)训练我们的模型识别异常值，并使用相同的标准来表示我们用于推理的异常值得分(第3.3节)。

### 3.1. 通过联合训练的正常化流产生异常

我们通过最小化内联的交叉熵($s^{ij} = 0$)和最大化粘贴底片的预测不确定性($s^{ij} = 1$)[14,18,29]来训练我们的==判别模型==:
$$
L(\theta) = \sum^{H,W}_{i,j}-(1-s^{ij}) \cdot ln \ p_{\theta}(y^{ij}|x') + \lambda \cdot s^{ij} \cdot L^{ij}_{neg}(\theta) \tag{2}
$$

> 对于每个像素$(i,j)$来说：
>
> - $s^{ij}$：正常 0，  异常 1
> - $ln\ p_{\theta}(y^{ij}|x')$ ：针对于正常像素（ID对象），交叉熵损失
> - $L_{neg}^{ij}(\theta)$：针对异常像素（OOD对象），辅助模型训练的正则项。选用JS散度

我们从联合训练的归一化流 $f_γ$ 中采样一个随机大小的负patch $x^-$。我们通过在内部训练图像 $x^+$ 上粘贴 $x^−$ 来组装混合内容训练图像 $x'$:
$$
x' = (1-s) \cdot x^+ + pad(x^-,s) \quad where \ x^- = f_{\gamma}^{-1}(z), \ z \sim \mathcal{N}(0,I) \tag{3}
$$
负片被贴在一个随机的位置上。异常点掩码s在随机选择的粘贴位置有1，其他地方有0。合成的离群点 $x^-$ 被填充为零，以允许通过加法粘贴。

> <img src="https://s1.vika.cn/space/2022/06/13/df2dc20f75dd41fba99e5b02a47ef0f8" alt="image-20220605211702179" style="zoom:70%;" />
>
> 图1：建议的训练设置。归一化流程产生了合成的负片 $x^-$，我们把它贴在原始的异常点图像 $x^+$ 上。由此产生的混合内容图像 $x^′$ 被送入密集分类器，该分类器被训练成能分辨出异常像素（$L_{cls}$），并能**对负面像素进行统一预测**（$L_{neg}$）。这种提法使梯度流从 $L_{neg}$ 流向归一化流，同时最大限度地提高离群斑点的似然（$L_{gen}$）。最好以彩色观看。





为了满足两个相反的标准，我们在训练主要判别模型的同时，也训练了归一化流（参见图1)。

- 首先，生成的样本应该在判别模型的输出端产生均匀分布。这==使生成的分布远离了局内点==。
- 第二，归一化流应该最大化局内补丁的似然，这==使生成分布向局内点移动==。

因此，这种训练鼓励在训练分布的边界生成合成样本，并将离群值意识纳入主要判别模型中[18]。联合训练程序最小化了以下损失。
$$
L(\theta,\gamma) = L_{gen}(\gamma)+\sum_{i,j}^{H,W}(1-s^{i,j}) \cdot L_{cls}^{i,j}(\theta)+\lambda \cdot s^{ij} \cdot L_{neg}^{ij}(\theta,\gamma) \tag{4}
$$
$L_{gen}$ 是我们用合成的离群点代替的局内点patch的负对数似然。$L_{cls}$ 是标准的判别损失。我们在下面的小节中仔细研究 $L_{neg}$。

### 3.2. 负数像素下的鲁棒性损失

损失 $L_{neg}$ 通常被设计为==均匀分布和模型预测分布之间的 KL-散度==[18, 21, 29]。然而，合成的异常点可能包含一些看起来像局内点的场景的块状部分。在这样的像素中，判别性预测是有信心的，这一点受到了KL-散度的强烈惩罚。这种损失使判别模型降低了对正常点内容的信心，因此引发了异常检测器频繁的假阳性反应。因此，我们在f-divergences的集合中寻找一个更稳健的损失函数

图2（左）显示了双类设置中各种f散度的损失值。我们观察到Jensen-Shannon散度对高置信度的预测有轻微的惩罚，这使它成为我们损失的合适候选者。图2（右）显示了每个像素损失的直方图，这表明JS散度在现实的设置中提供了强大的惩罚作用。请注意，其他f散度，如Pearson或Hellinger散度，甚至比KL散度更严格。

> <img src="https://s1.vika.cn/space/2022/06/13/c4319e15b0eb43139ffbe95b03b91dc8" alt="image-20220606082805301" style="zoom:60%;" />
> 图2：在两类设置中对均匀分布的F散度（左）。JensenShannon提供了最稳健的反应。在我们的设置中，在联合训练开始时，λLneg在合成阴性体中的直方图（右)。调制因子λ已经分别对Lneg的三种选择进行了验证。Jensen-Shannon散度产生的学习信号比其他f散度更均匀。最好以彩色观看。

### 3.3. 基于散度分数的推理

与所有现有的设计相反，我们建议通过使==评分函数与训练目标相一致==来进行推理。图3说明了由此产生的密集开放集识别方法。输入的图像被送入判别模型。产生的对数被送入两个分支。

> <img src="https://s1.vika.cn/space/2022/06/13/7cdf7f047c564bdea53615cd21163eff" alt="image-20220606082907607" style="zoom:67%;" />
> 图3：建议的开放集推理。首先，我们用主要的稠密预测模型进行推理。我们根据我们基于散度的得分（JSD）恢复OOD图。只要OOD得分超过阈值δ，封闭集预测就会被覆盖（最终开放集输出中的白色像素)。 最佳的彩色视图。

顶部的分支通过arg-max提供封闭集预测。底部分支通过温度缩放、softmax和相对于均匀分布的JS散度来恢复密集的异常图。这两个分支被融合成最终的开放集分割图。只要异常得分超过整个数据集的阈值，异常图就会覆盖封闭集的预测。

我们使用**温度标度**[5]，因为与具有齐次非最大对数的分布相比，具有两个显性对数的分布的相对异常分数降低。这阻止了语义边界处的假阳性OOD反应。我们在所有的实验中使用相同的温度T=2，将我们的性能与以前的方法进行比较。请注意，我们的推断是非常快的，因为我们在训练期间只使用生成模型来模拟异常情况。这与图像重合成不同，在推理过程中必须使用生成模型。

## 4. 实验设置

本节介绍了我们的密集型异常检测的实验设置。我们回顾了所采用的数据集，介绍了性能指标，并描述了训练程序的细节。

### 4.1. 基准和数据集

近年来，对道路驾驶场景中的异常检测性能进行基准测试取得了重大进展。早期的方法[15]将异常点粘贴在道路驾驶场景顶部的随机位置（参见图4，左）。这被一种更先进的粘贴策略进一步改进，该策略适应阴影和照明[12]（参见图4，中间）。最近的数据集避免了物体的粘贴。相反，他们使用真实的图像，其中的异常点与环境完全一致[39]（参见图4，右）。同时，通过利用模拟环境，在人工数据集方面也投入了大量的精力[40]。模拟环境为异常点的插入和操作提供了更多的自由。

> ![image-20220607083028293](https://s1.vika.cn/space/2022/06/13/8d1c091f46dc4ea587fbf79b906ebabf)
>
> 图4：密集型异常检测数据集在时间上的进展。早期的工作是将物体粘贴到随机位置[15]。通过仔细选择粘贴位置和后处理进一步改进[12]。最近的工作通过选择充分的真实世界场景确保异常点与环境相匹配[39]。最好以彩色观看。

$WD-Pascal^1$ [15]是一个异常检测数据集，通过将Pascal VOC对象粘贴到WildDash[6]图像中而创建。由于WildDash图像所捕捉到的场景很困难，因此对其进行分割是很有挑战性的。由此产生的数据集可以在苛刻的条件下评估异常检测。然而，如图4（左）所示，随机粘贴的策略干扰了场景。因此，有可能这种异常现象更容易被检测到。

**Fishyscapes**[12]评估了模型在城市驾驶场景中检测异常的能力。该基准由两个数据集组成。FS LostAndFound和FS Static。FS LostAndFound是原始LostAndFound[41]的一个小子集，它包含道路上的小物体（如玩具、盒子或可能掉落的汽车零件）。FS Static包含Cityscapes验证图像，上面覆盖着Pascal VOC物体。这些物体被定位以模仿真实世界，并进一步进行后处理以获得更平滑的异常注入场景。

**SegmentMeIfYouCan**（SMIYC）[39]量化了多种设置中的密集异常检测性能。该基准由三个数据集组成。AnomalyTrack、ObstacleTrack和LostAndFound[41]。AnomalyTrack提供了与环境完全一致的大型异常物体。例如，他们在一条土路中间有一只豹子，如图4（右）所示。LostAndFound[41]测试了对城市场景中小型危险物体（如箱子、玩具、汽车零件等）的检测。最后，ObstacleTrack测试了对各种类型道路上小物体的检测。不一致的路面会欺骗检测器，增加假阳性率。因此，SMIYC对部署在野外的模型的异常分割性能提供了一个可靠的概念。

**StreetHazards**[40]是一个用CARLA游戏引擎创建的合成数据集。该数据集捕获了模拟的城市环境，并精心插入了异常物体（例如停在路上的马车或直升机）。在虚拟环境中模拟异常现象是很有吸引力的，因为在异常现象的定位和外观方面有很高的灵活性，而且数据积累的成本很低。不幸的是，模拟环境和真实世界之间存在着明显的质量不匹配。尽管如此，这种方法在评估各种形式的异常检测方面仍有很大潜力。

### 4.2. 评价指标

我们使用平均精度（AP）和真阳性率为95%时的假阳性率（FPR95）[12]来衡量异常分割的性能。AP很适合用来衡量异常检测性能，因为它强调对少数类的检测。一个完美的分类器的AP等于1。同样，FPR95对现实世界的应用也很重要，因为在实际部署中，高假阳性率需要大量的人工干预，因此严重削弱了自主系统的实用价值。

### 4.3. 实施细节

我们所有的模型都是基于Ladder-DenseNet（LDN）架构，因为它的内存效率和在2MPix上的近乎实时的性能[35]。然而，我们的框架可以容纳任何其他密集预测架构。我们所有的实验都包括两个训练阶段。在这两个阶段，我们利用Cityscapes、Vistas和Wilddash 2 [6]。这三个数据集包含25 231张图像。这些图像被调整为1024像素（短边），以0.5的概率随机翻转，在[0.5, 2]的区间内随机调整大小，并随机裁剪为768×768像素。我们用Adam优化器优化我们的模型。

- 在第一阶段，我们在没有合成异常的情况下训练了25个 epochs。我们使用批量大小为16，这在以前的工作中得到验证[35]。特征提取器的起始学习率被设置为$10^{-4}$ ，上升采样路径的学习率为$4 * 10^{-4}$。学习率根据余弦计划被退火到最小值$10^{-7}$，这将在第50个epoch中达到。

- 在第二阶段，我们在混合内容的图像上训练15个 epochs，如第3.1节所述。在这个阶段，我们使用12个批处理，因为这是一个具有24GB内存的GPU可以容纳的最大批处理。请注意，我们使用梯度s检查点[35]。最初的学习率被设定为上采样路径的$10^{-5}$和骨干路径的$2.5 * 10^{-6}$。再一次，学习率根据余弦时间表衰减到$10^{-7}$的值。我们将超参数λ设置为$3 * 10^{-2}$。这个值的选择是以不降低主要分割任务的性能为前提的。

我们的归一化流程在[16, 216]范围内生成具有随机空间尺寸的矩形异常斑块。该流程在Vistas的随机64×64农作物上进行了预训练。我们用Adamax优化器训练该流程，学习率设置为$10^{-6}$。

在WD-Pascal的情况下，我们只在Vistas上训练我们的模型，以实现与以前的工作[15]的公平比较。在StreetHazards的案例中，我们在相应的训练子集上训练了80个epochs的inlier图像和40个epochs的混合内容图像。在Fishyscapes的情况下，我们只对城市景观进行训练。我们在第一阶段训练150个历时（离群值），在第二阶段训练50个历时（混合内容）。所有其他超参数在所有实验中保持不变。每个实验在一台NVIDIA RTX A5000上持续了大约38小时。

## 5. 实验评估

我们在WD-Pascal、Fishyscapes、SegmentMeIfYouCan和StreetHazards上评估我们的方法。我们将我们的性能与那些不需要负面数据集或图像重新合成的当代方法进行比较。不过，我们还是在表格中列出了所有的方法，这样我们就可以在一个更广泛的背景下讨论我们的方法。我们还分析了我们的方法对异常点与摄像机的距离的敏感性。最后，我们衡量了我们的方法相对于基线分割模型的计算开销，可视化我们的合成异常点，并消除了提议的贡献。

### 5.1.WD-PASCAL的性能评价

表1列出了在WD-Pascal上运行50次的性能[15]。下面的部分将我们的方法与早期的方法进行了比较。MC dropout [10], ODIN [24], 和max-softmax [21]。这些方法与目前最先进的方法相比没有竞争力。

上面的部分显示，用辅助的负数据进行训练可以显著提高性能。然而，我们的方法缩小了性能差距。它在FPR95和AUROC指标上优于所有其他方法，同时取得了有竞争力的AP。

> <img src="https://s1.vika.cn/space/2022/06/13/f33282a1f6d248019a15d76916d767df" alt="image-20220608113927049" style="zoom:50%;" />
> 表1：WD-Pascal[15]上的性能评估。我们的方法在FPR95和AUROC中优于所有其他方法，同时取得了有竞争力的AP。

### 5.2.  FISHISCAPE基准的性能评估

> <img src="https://s1.vika.cn/space/2022/06/13/6619f3e6183f41cdbce6c49e641c6840" alt="image-20220608113820228" style="zoom:50%;" />
> 表2: Fishyscapes基准测试的结果。在FS L&F上，我们的方法产生了最好的FPR95和第二好的AP。在FS Static上，我们的方法在不使用负面数据的方法中取得了最好的FPR95和第二好的AP。

表2显示了对Fishyscapes基准的性能评估。我们的合成负面数据成功地与FS LostAndFound的负面训练数据打成平手。我们的方法在FPR95方面优于以前的所有方法，同时取得了第二好的AP，仅在SynBoost方面表现稍差，因为SynBoost是在真实的负面数据上进行训练，不可能进行实时推理。

表的最后一节显示了我们方法的一个变体，它在推理过程中关注地面（GF代表地面关注）。我们将地面定义为一个凸包，覆盖所有被预测为道路或人行道的像素。这一变化带来了两个指标的巨大改善。

在FS静态数据集的情况下，我们的方法在不对辅助数据进行训练的方法中取得了最好的FPR95和第二好的AP。由于负面训练数据和测试图像中的实际异常情况之间可能存在一致性，对辅助负面数据进行训练可能导致性能评估过于乐观。

### 5.3. MeIfYouCan的效果评估

表3是对SMIYC基准的性能评估。我们的方法优于之前所有使用图像重新合成[8, 9, 7]、部分图像重建[31]或辅助数据利用[12]的方法。

> <img src="NFlowJS.assets/image-20220608113733452.png" alt="image-20220608113733452" style="zoom:50%;" />
> 表3：SMIYC的异常检测性能。我们的表现超过了所有其他方法。我们的方法具有较低的FPR，这使得它特别适用于现实世界的应用。

我们的方法在ObstacleTrack和LostAndFound-noKnown上实现了非常低的FPR95（低于1%）。这对现实世界的应用特别重要，在那里，假阳性的高发生率可能使异常检测失去作用。请注意，ObstacleTrack包括各种路面前面的小异常，这使得它很难不把道路部分误归为异常。此外，这个数据集包括黄昏时分拍摄的低能见度图像和其他具有挑战性的评估设置。对SMIYC基准的更详细的性能评估见附录A。

图5显示了所提方法在SMIYC LostAndFound数据集的两个图像序列上的表现。灰色为道路实况，黄色为预测的异常情况。上面的序列包含一个异常物体，其位置随时间变化。下面的序列包含多个异常物体。我们的方法成功地检测到了一辆玩具车和纸板箱，尽管在训练期间没有这样的物体出现。

> <img src="https://s1.vika.cn/space/2022/06/13/f5f7db555aca4369a306f6b9605fbae8" alt="image-20220608093015083" style="zoom:50%;" />
> 图5：LostAndFound数据集的异常检测。我们的方法可以检测到离摄像机不同距离的异常情况（上图），以及一张图片中的多个异常情况（下图)。灰色为道路实况，黄色为预测的异常点。最好以彩色观看。

图6显示了我们的方法在两个因汽车头灯而过度曝光的夜景中的表现。两张图片都属于ObstacleTrack测试集。我们在第二栏中显示了我们密集的异常得分。第三列显示了融合的开放集分割图，异常像素以白色表示。我们使用OOD阈值，该阈值在相应的验证集上给出了小于1%的FPR。

> <img src="https://s1.vika.cn/space/2022/06/13/6a20a729b27d44dc94321a81a9f3a6b6" alt="image-20220608112749333" style="zoom:67%;" />
> 图6：SMIYC-ObstacleTrack的两个夜景中的异常检测。第一列显示输入图像。第二列显示我们密集的异常得分。第三列显示融合的开放集分割图。最好以彩色观看。

### 5.4.关于StreetHazards的性能评估

表4是对StreetHazards的性能评估。据我们所知，我们的方法大大超过了以前的所有工作。特别是，我们的方法比基于条件随机场[40]、图像再合成[30]和通过对训练期间积累的权重分布进行抽样形成的网络集合[43]的方法更好。

> <img src="https://s1.vika.cn/space/2022/06/13/774e5f4ce0094251971b56b84a037f50" alt="image-20220608125831063" style="zoom:50%;" />
> 表4：在StreetHazards[40]数据集上的表现。我们的方法在密集异常检测方面优于所有其他方法。

### 5.5. 异常检测对距摄像机距离的敏感性

我们分析了Fishyscapes和SMIYC中包含的LostAndFound数据集的异常检测对摄像机距离的敏感性。测试集由1203张图像和相应的像素级差异图组成，在此基础上我们计算了与自我车辆（ego-vehicle）的距离。由于可用差距的限制，我们在距离相机5到60米的范围内进行分析。

图7（左）显示了异常点和非异常点像素的直方图。该图显示，62.5%的异常像素的距离小于15米。因此，通常的指标都是偏向于更近的范围。事实上，正如我们进一步证明的那样，许多方法在较远的距离上都无法检测到异常点。

> <img src="https://s1.vika.cn/space/2022/06/13/01bd42dd917848f89aa80d1947fc5bc4" alt="image-20220608131438826" style="zoom:70%;" />
> 图7：左图：LostAndFound测试集像素的直方图。右图。在与自我车辆的不同距离上，TPR为95%时的FPR分析。最好以彩色观看。

我们将我们的方法与max-logit和max-softmax[21]基线、ODIN[24]、SynBoost[7]和OOD head[15]进行比较，后者是在有噪声的负面数据上进行训练。表5显示，这些方法产生了很高的假阳性率，甚至在小范围内也是如此，这使得它们实际上是无用的。

> <img src="https://s1.vika.cn/space/2022/06/13/98751173abdc4f84975bdf6f90d46d87" alt="image-20220608132243126" style="zoom:50%;" />
> 表5：在距摄像机不同距离的TPR为95%时的FPR分析。由于所有距离的FPR率都非常低，我们的方法是现实世界应用的最佳选择。

图7（右）将我们的方法的相对性能与异常点的距离分层。除了在近距离（5-10米）我们的方法与SynBoost[7]的表现相当外，我们的方法在所有距离上都以很大的优势战胜了以前的工作。

### 5.6. 推理速度

一个方便的密集异常检测器不应该大幅增加已经很重的语义分割的计算负担。因此，我们测量了我们方法的计算开销，并将其与其他方法进行了比较。我们在NVIDIA RTX 3090上测量1024×2048输入的推理速度。表6显示，SynBoost[7]和SynthCP[30]不适用于实时推理，因为它们需要超过一秒钟。基准模型LDN-121[35]对两百万像素的图像实现了接近实时的推理（46.5毫秒，21.5FPS）。ODIN[24]需要一个额外的前向-后向通道，以恢复损失相对于图像的梯度。这导致与基线相比，速度下降了3倍。同样地，MC Dropout[10]需要K个前向通道来预测K个MC样本。当只使用2个MC样本时，这导致了45.8毫秒的开销。相反，我们的方法只比基线增加了7.8毫秒的推理时间，同时优于以前的所有方法。请注意，SynthCP的结果取自于[42]。

> <img src="https://s1.vika.cn/space/2022/06/13/cc77883c89f8492e915c4faa5c1523df" alt="image-20220608133546534" style="zoom:67%;" />
> 表6：选定的密集预测方法的推理速度比较。我们的方法只需要7.8ms的开销来产生密集异常图，而当代的方法[7, 24, 10]则不适用于实时推理。

### 5.7. 合成离群点的可视化

我们的归一化流量模型能够用同一模型生成多个分辨率的样本。与典型的负面数据集如ImageNet相比，生成的样本种类有限。尽管如此，用它们进行训练还是大大减少了过度自信，因为模型被明确地训练为区分已知和未知的东西。图8显示了如第3.2节所述的联合训练的归一化流程的样本。

> <img src="https://s1.vika.cn/space/2022/06/13/9d5702f555404b1fa4a5844fb90bd7c4" alt="image-20220608133854481" style="zoom:67%;" />
> 图8：我们的生成模型DenseFlow-25-6的样本，它与我们在第3.1节中提出的开放集分割模型共同训练。



### 5.8. 损失函数和异常分数的影响

> <img src="https://s1.vika.cn/space/2022/06/13/b0061543ba744912ae19e799056d0831" alt="image-20220608134144068" style="zoom:50%;" />
> 表7：负数像素中损失函数的分析。基于JS-散度的损失函数优于标准的KL-散度损失（第4行对第1行）。使用JSD评分检测异常情况优于标准的临时标准（第5行与第4行)。

表7分析了损失函数（$L_{neg}$）和负像素中的异常得分（$s_δ$）对大（AnomalyTrack val）和小异常（ObstacleTrack val）的影响。我们分别验证了每个选择的负损失的调制因子$λ$，以及温度参数。我们对 max-softmax 极限使用$T=10$，对基于散度的评分函数使用$T=2$。我们报告了过去三个epoch的平均性能。第1行显示了标准设置，其中损失函数是均匀分布和softmax输出之间的KL散度[18, 14]，而异常得分是maxsoftmax。第2行的特征是KL散度既是损失函数又是异常得分。第3行的特征是反转KL散度。最小化统一分布和softmax分布之间的反向散度等同于最大化softmax熵。第4行和第5行是JS散度。我们观察到，反向KL散度在4个指标中的3个指标中优于标准设置。无论是作为损失函数（JSD-MSP vs KL-MSP）还是作为异常得分（JSD-JSD vs JSD-MSP和RKLRKL），JS散度都大大优于所有替代方案。我们将这一优势解释为对类似于离群点的合成离群点的稳健响应，以及在训练和评分过程中改进的一致性（参见3.2和3.3节）。

### 5.9. 预训练的影响

> <img src="https://s1.vika.cn/space/2022/06/13/846f5b09ddcf4c6ab402e808a61ddd1b" alt="image-20220608134950887" style="zoom:50%;" />
> 表8：模型预训练对异常检测性能的影响。在联合训练之前对两个模型进行预训练是有益的。

表8显示了预训练对异常检测性能的影响。第1行显示了在联合训练（第3.1节）之前既不训练生成性模型也不训练鉴别性模型时的性能。在这种情况下，我们从各自的初始化中联合训练两个模型。第2行显示，分类器预训练提高了异常检测的效果。在初始训练阶段之后才引入合成异常点，可以防止过度拟合。第3行显示，由于生成的异常现象的质量更好，对两个模型进行预训练会产生更好的性能。我们还注意到，利用RealNVP[19]而不是DenseFlow[38]降低了样本质量，使异常检测性能下降到AnomalyTrack val的61.6% AP和ObstacleTrack val的94.9% AP。

### 5.10. 温度缩放的影响

表9显示了softmax重新校准对异常检测的影响。该表显示了温度为T=1、T=1.5和T=2的SMIYC值的性能。我们观察到，温度的缩放明显改善了基于散度的评分。

> <img src="https://s1.vika.cn/space/2022/06/13/ba97805e78d74f579beae9a10d4b0ff1" alt="image-20220608134933639" style="zoom:50%;" />
> 表9：softmax的重新校准对密集型异常检测的影响。温度标度提高了我们基于散度的异常检测器。



## 6. 结论

我们提出了一种新的密集异常检测和Openset识别方法。我们的方法在混合内容的图像上进行训练，这些图像是通过将合成阴性斑块粘贴到训练图像中获得的。我们通过对生成模型进行采样来产生合成负片，生成模型被联合训练以最大化可能性并在判别模型的远端产生统一预测。这种协作学习导致了保守的未知预测，适合于异常检测和开放集识别

我们通过以下贡献来扩展以前的工作。首先，我们用一个归一化流程取代了对抗性生成模型（GAN）。我们认为，由此带来的改进是由训练分布的更好覆盖造成的。第二，我们为密集预测调整了协作训练的设置。生成流特别适合于这项任务，因为它可以在不同的分辨率下直接生成。第三，我们建议通过在联合训练前预训练归一化流和判别模型来防止判别模型对合成异常现象的过度拟合。第四，我们建议使用JS散度作为训练合成异常的判别模型的有力标准。我们还表明，同样的标准可以作为有原则的、有竞争力的替代临时评分函数（如max-softmax）。

我们在密集异常检测的标准基准和数据集上评估了所提出的方法。结果表明，在7个评估数据集中，有6个数据集的性能是最先进的，与之前所有不在真实负面数据上训练的方法相比，有很大的优势，而且与密集预测基线相比，开销非常低。因此，所提出的方法适用于实时应用。未来工作的合适途径包括允许我们的方法在真实的负面数据上进行训练，并将其扩展到其他密集预测任务。







