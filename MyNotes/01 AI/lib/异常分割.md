Maximum Softmax Probability —— 最大softmax概率，异常分割中一种有效方法


前面直接用语义分割网络的方法Maxlogit,MSP,原型学习都只用在正常像素上训练一个语义分割模型就行

利用不确定度的方法是根据测试时正常像素经过训练后输出的分类分数高，异常像素没有经过训练输出的分类分数低（不属于任何一个正常类或者不确定属于正常类的哪一类）
不确定度方法存在的问题
1. 物体轮廓处（处于几个类别边缘）的正常像素会有低的分类得分，分类错误的正常像素会有低的分类得分，导致假阳性
2. 神经网络的过度自信，异常物体内部也会因为分类得分高导致假阴（为什么会导致这种结果，内部和已知类很像？ #promlem ）


重建方法利用的是测试时异常像素经过语义分割分为正常类的一类，重建图重建不出异常类，比较原图和重建图来定位异常

重建方法存在的问题:
1. 一个正常像素（如天空），语义分割网络分成了大地，那么重建成大地，比较原图和重建图就会误检造成假阳性（比较依赖分割网络的性能）；
2. 一个正常像素（如天空），语义分割网络分成了天空，生成网络错误重建为大地，比较原图和重建图也会误检造成假阳性（比较依赖GAN网络的性能）

用到差异网络的重建方法训练的时候必须要**引入异常**，不然输入网络的只是正常图片的话，网络的输出和监督的标签就是一个全0的东西（全正常），那么网络会学习把任意输入都映射为0，而我们希望网络训练学习之后能把正常打分接近为0，异常打分接近于1，所以在训练的时候我们就要在训练图片中产生异常，相应的监督lable是正常像素对应为0，异常像素对应为1



[[Max Logits]]
[[SML]]
[[PAnS]]

[[SynthCP]]

[[CosMe]]
[[一类嵌入反向蒸馏]]

[[DMLNet]]

[[NFlowJS]]

[[PEBAL]]




[[语义分割的评价指标]]在异常分割中，往往也是适用的。