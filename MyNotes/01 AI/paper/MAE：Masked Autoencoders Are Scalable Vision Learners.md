- tag: #AI/Transformer #AI/Contrastive #AI/Self-supersived 
- Pdf：[[Masked Autoencoders Are Scalable Vision Learners.pdf]]


和之前文章的联系
- [[Transformer]]: 完全基于 Attention 的 Encoder 和 Decoder。
- [[BERT]]: 使用 Transformer Encoder，完形填空自监督训练机制
- [[vit]]: Transformer 用到CV上
- MAE: Bert 的CV版本。


[[auto]]自模型：标号x 和样本y 来自于同一个东西

论文标题模版： xxx 是一个好的 xxx（比较客观，包含结论）


- 文本信息：信息集中，基本不能去掉字词。
- 图片信息：信息比较冗余，去掉大部分的 patch 会让其他保留的 patch 冗余很少，使模型学到一个全局的信息，不关注局部



## 带掩码的自编码器是一个可拓展的视觉学习器

### 概述
本文表明，掩码自动编码器（MAE）是计算机视觉中可扩展的自监督学习器。我们的MAE方法很简单：我们对输入图像的随机 patch 进行屏蔽，并重建缺失的像素。它基于两个核心设计。首先，我们开发了一个非对称的编码器-解码器架构，其中的编码器只对可见的 patch 子集进行操作（没有掩码 token ），同时还有一个轻量级的解码器，从潜在的表示和掩码 token 中重建原始图像。其次，我们发现，对输入图像的高比例进行掩码，例如75%，会产生一个不难的、有意义的自我监督任务。耦合这两个标志使我们能够有效地训练大型模型：我们加速了训练（3倍或更多）并提高了准确性。我们的可扩展方法允许学习具有良好泛化能力的高容量模型：例如，在只使用ImageNet-1K数据的方法中，一个虚构的ViT-Huge模型实现了最佳的准确性（87.8%）。在下游任务中的转移性能优于有监督的预训练，并显示出有希望的扩展行为。


### 1. 介绍
深度学习已经见证了能力和容量持续增长的架构的爆炸[33, 25, 57]。在硬件快速发展的帮助下，今天的模型可以很容易地超配一百万张图像[13]，并开始需要数以亿计的--通常是公众无法获得的-- labeled的图像[16]。

在自然语言处理（NLP）中，这种对数据的渴求已经通过自我监督的预训练成功解决。基于GPT[47, 48, 4]中的自回归语言建模和BERT[14]中的屏蔽式自动编码的解决方案在概念上很简单：它们删除一部分数据并学习预测删除的内容。这些方法现在能够训练包含一千多亿个参数的可推广的NLP模型[4]。

掩蔽自动编码器的想法，是更多源性去噪自动编码器的一种形式[58]，在计算机视觉中也很自然和适用。事实上，视觉中密切相关的研究[59, 46]早于BERT。然而，尽管在BERT成功之后，人们对这个想法产生了极大的兴趣，但视觉中的自动编码方法的进展却落后于NLP。我们问：是什么让遮蔽式自动编码在视觉和语言之间有所不同？我们试图从以下几个方面来回答这个问题：
1. 直到最近，架构是不同的。在视觉方面，卷积网络[34]在过去十年中占主导地位[33]。卷积通常在规则的网格上运行，将 "指标 "如掩码 token [14]或位置嵌入[57]整合到卷积网络中并不简单。然而，随着视觉转换器（ViT）[16]的引入，这一架构上的差距已经得到解决，应该不再是一个障碍。
2. 语言和视觉之间的信息密度是不同的。语言是人类产生的信号，具有高度的语义和信息密度。当训练一个模型来预测每个句子中仅有的几个缺失的单词时，这项任务似乎会引起复杂的语言理解。相反，图像是具有严重空间冗余的自然信号--例如，一个缺失的掩码可以从邻近的掩码中重新覆盖，而对部分、物体和场景的高级理解却很少。为了克服这种差异并鼓励学习有用的特征，我们表明一个简单的策略在计算机视觉中很有效：对随机掩码的一个非常高的部分进行遮蔽。这一策略在很大程度上减少了冗余，并创造了一个具有挑战性的自我监督任务，需要超越低层次图像统计的整体理解。为了获得我们重建任务的定性意义，请看图2 - 4。
3. 自动编码器的解码器，将潜在的表征映射回输入，在重建文本和图像之间扮演着不同的角色。在视觉中，解码器重建像素，因此其输出的语义水平比普通的识别任务要低。这与语言不同，在语言中，解码器预测的是包含丰富语义信息的缺失词。虽然在BERT中，解码器可以是微不足道的（MLP）[14]，但我们发现，对于图像来说，解码器的设计在决定所学的潜在表征的语义水平方面起着关键作用。

在这一分析的推动下，我们提出了一个简单、有效、可扩展的用于视觉表征学习的掩码自编码器（MAE）。我们的自动编码器对输入图像的随机 patch 进行屏蔽，并在像素空间内重建缺失的 patch 。它有一个不对称的编码器-解码器设计。我们的编码器只在可见的 patch 子集上操作（没有遮罩 token ），而我们的解码器是轻量级的，并从潜在的再现和遮罩 token 一起重建输入（图1）。在我们的非对称编码器-解码器中，将掩码 token 转移到小的解码器，导致计算量大大减少。
在这种设计下，一个非常高的屏蔽率（如75%）可以实现双赢的局面：它优化了准确性，同时让编码器只处理一小部分（如25%）的 patch 。这可以使整个预训练时间减少3倍或更多，同样也可以减少内存消耗，使我们能够轻松地将我们的MAE扩展到大型模型。

我们的MAE可以学习到非常高容量的模型，并且具有良好的泛化能力。通过MAE的预训练，我们可以在ImageNet-1K上训练像ViT-Large/-Huge[16]这样的高耗能模型，并提高泛化性能。通过一个普通的ViT-Huge模型，在ImageNet-1K上进行微调后，我们达到了87.8%的准确性。这超过了之前所有只使用ImageNet-1K数据的结果。我们还评估了对象检测、实例分割和语义分割的迁移学习。在这些任务中，我们的预训练取得了比有监督的预训练同行更好的结果，更重要的是，我们通过扩大模型的规模观察到了明显的收益。这些观察结果与NLP中的自监督预训练中的观察结果一致[14, 47, 48, 4]，我们希望它们能使我们的领域探索出一条类似的轨迹。

![image.png](https://s1.vika.cn/space/2023/02/10/5338137ce6864b3ab7c4d73bb8dba48b)

![image.png](https://s1.vika.cn/space/2023/02/10/28f1fcfbbe424c90940208021a513405)


![image.png](https://s1.vika.cn/space/2023/02/10/d3e27a64d9ac49d08bb5cf6eb76feb67)


### 2. 相关工作
**掩码语言建模**及其自回归模型，如BERT[14]和GPT[47, 48, 4]，是NLP中非常成功的预训练方法。这些方法保留了输入序列的一部分，并训练模型来预测缺失的内容。这些方法已被证明可以很好地扩展[4]，大量的证据表明，这些预训练的代表可以很好地遗传给各种下游任务。

**自编码**是一种学习表征的经典方法。它有一个将输入映射到潜在表征的编码器和一个重构输入的解码器。例如，PCA和K-means是自动编码器[29]。去噪自动编码器（DAE）[58]是一类自动编码器，它破坏输入信号并学习重建原始的、未被破坏的信号。一系列的方法可以被认为是在不同的损坏情况下的广义DAE，例如，掩盖像素[59, 46, 6]或去除颜色通道[70]。我们的MAE是去噪自动编码的一种形式，但在许多方面与经典的DAE不同。

**屏蔽图像编码**方法从被屏蔽破坏的图像中学习表征。[59]的开创性工作将遮蔽作为DAE中的一种噪声类型。Context Encoder[46]使用卷积网络对大的缺失区域进行涂抹。在NLP成功的激励下，最近的相关方法[6, 16, 2]是基于变形器[57]的。iGPT[6]对像素序列进行操作并预测未知的像素。ViT论文[16]研究了用于自我监督学习的遮蔽 patch 预测。最近，BEiT[2]提出预测离散的 token [44, 50]。

**自监督学习**方法在计算机视觉中受到了极大的关注，通常专注于不同的预训练任务[15, 61, 42, 70, 45, 17]。最近，对比学习[3, 22]很受欢迎，例如，[62, 43, 23, 7]，它对两个或多个视图之间的图像相似性和不相似性（或仅相似性[21, 8]）进行建模。对比法和相关方法强烈地依赖于数据增强[7, 21, 8]。自动编码追求的是一个概念上不同的方向，它表现出不同的行为方式，我们将介绍。

### 3. 方法
我们的掩码自动编码器（MAE）是一种简单的自动编码方法，它可以根据部分观察结果重建原始信号。像所有的自动编码器一样，我们的方法有一个编码器，将观察到的信号映射到一个潜在的表示，还有一个解码器，从潜在的表示中重建原始的信号。与经典的自动编码器不同，我们采用了一种非对称的设计，允许编码器只对部分观察到的信号进行操作（没有掩码 token ），而一个轻量级的解码器则从潜像表示和掩码 token 中重新构建完整的信号。图1说明了这个想法，接下来介绍。
![image.png](https://s1.vika.cn/space/2023/02/10/2fd25f225b0644599f001c30500b1eff)

**掩码。** 按照ViT[16]的做法，我们将一幅图像分成若干个不重叠的 patch 。然后，我们对 patch 的一个子集进行抽样，并对剩余的 patch 进行遮蔽（即，移除）。我们的取样策略很简单：我们按照统一的分布方式，不加替换地随机取样。我们简单地将其称为 "随机抽样"。

具有高遮蔽率的随机抽样（即被移除的 patch 的比例）在很大程度上消除了冗余，从而创造了一个不容易通过从可见的相邻 patch 推断来解决的任务（见图2-4）。均匀分布防止了潜在的中心偏向（即在图像中心附近有更多的遮蔽 patch ）。最后，高度稀疏的输入为设计一个高效的编码器创造了机会，接下来介绍。

**MAE编码器。** 我们的编码器是一个ViT[16]，但只适用于可见的、未被掩盖的 patch 。就像在标准的ViT中一样，我们的编码器通过线性投影嵌入 patch，并添加位置嵌入，然后通过一系列的Transformer块来处理结果。然而，我们的编码器只对全集的一个小子集（如25%）进行操作。
屏蔽的 patch 被移除；不使用屏蔽 token。这使我们可以用少量的计算和内存来训练非常大的编码器。全集由一个轻量级的解码器来处理，接下来介绍。

**MAE解码器。** MAE解码器的输入是由(i)编码的可见 patch 和(ii)掩码 token 组成的全套集合。见图1。每个掩码 token [14]是一个共享的、学习过的向量，表示要预测的失误 patch 的存在。我们对这一完整集合中的所有 token 添加位置嵌入；如果没有这一点，掩码 token 将没有关于它们在图像中的位置的信息。解码器有另一系列的 Transformer 块。

MAE解码器只在预训练期间用于执行图像重建任务（只有编码器用于产生用于识别的图像表示）。
因此，解码器的结构可以以独立于编码器设计的方式灵活地设计。我们尝试使用非常小的解码器，比编码器更窄、更低的解码器。例如，我们的默认解码器与编码器相比，每个 token 的计算量<10%。通过这种不对称的设计，全套的 token 只由轻量级的解码器处理，这大大减少了预训练时间。

**重构目标。** 我们的MAE通过预测每个被遮蔽的 patch 的像素值来重建输入。解码器输出中的每个元素都是代表一个 patch 的像素值的向量。解码器的最后一层是一个线性投影，其输出通道的数量等于一个 patch 的像素值的数量。解码器的输出被重塑以形成一个重建的图像。我们的损失函数计算重建图像和原始图像之间在像素空间的平均平方误差（MSE）。我们只在被遮蔽的 patch 上计算损失，与BERT[14]类似。我们还研究了一个变体，其重建目标是每个被遮蔽 patch 的归一化像素值。具体来说，我们计算一个 patch 中所有像素的平均值和标准偏差，并使用它们来规范这个 patch 。在我们的实验中，使用归一化的像素作为重建目标可以提高表示质量。

**简单实施。** 我们的MAE预训练可以有效地实施，而且重要的是，不需要任何专门的稀疏操作。首先，我们为每一个输入 patch 生成一个 token （通过线性投影和一个附加的位置嵌入）。接下来，我们根据掩蔽率，随机shuffle token列表并删除列表的最后一部分。这个过程为编码器产生了一个小的 tokens 子集，相当于无替换地对 patch 进行采样。编码后，我们在编码 patch 的列表上附加一个掩码 token 的列表，并解开这个完整的列表（倒置随机 shuffle 操作），使所有 token 与它们的目标对齐。解码器被应用于这个完整的列表（加入位置嵌入）。如前所述，不需要任何稀疏操作。这个简单的实现引入了可忽略不计的开销，因为 shuffle 和取消 shuffle 的操作都很快速。

### 4. ImageNet 实验
我们在ImageNet-1K（IN1K）[13]训练集上进行自我监督的预训练。然后我们进行监督训练，用（i）端对端微调或（ii）线性探测来评估表征。我们报告了单个224×224作物的top-1验证精度。细节见附录A.1。

**基线。ViT-Large。** 我们使用ViT-Large（ViT-L/16）作为消融研究的主干。ViT-L非常大（比ResNet-50[25]大一个数量级），倾向于过度拟合。以下是ViT-L从头开始训练与从我们的基线MAE微调的比较：
![image.png](https://s1.vika.cn/space/2023/02/13/8ec5b8f04aec43b0b9802c783c015cf3)
我们注意到，从头开始训练有监督的ViT-L是不容易的，需要一个具有强大正则化的好配方（82.5%，见附录A.2）。即便如此，我们的MAE预训练还是带来了很大的改进。这里的微调只针对50个epochs（相对于从头开始的200个），这意味着微调的准确性在很大程度上取决于预训练。

#### 4.1. 主要属性
我们使用表1中的默认设置来消减我们的MAE（见标题）。观察到几个耐人寻味的特性。
![image.png](https://s1.vika.cn/space/2023/02/13/09e5a9f5b0af431da002aad8608730c3)


![image.png](https://s1.vika.cn/space/2023/02/13/7a818f92817640318adc5f6ef2eaa9f2)

**掩蔽率。** 图5显示了遮蔽比率的影响。最佳比率是令人惊讶的高。75%的比率对线性探测和微调都很好。
这种行为与BERT[14]形成对比，后者的典型掩蔽率为15%。我们的遮蔽率也比计算机视觉领域的相关工作[6, 16, 2]的遮蔽率高得多（20%到50%）。

该模型推断出缺失的斑块，以产生不同的、但合理的输出（图4）。它使物体和场景的完形填空（gestalt）有了意义，这不能简单地通过延长线条或纹理来完成。我们假设，这种类似推理的行为与学习有用的表征有关。

图5还显示，线性探测和微调的结果遵循不同的趋势。对于线性探测，准确率随着掩蔽比率的增加而稳步上升，直到甜蜜点：准确率差距高达20%∼（54.6%与73.5%）。对于微调，结果对比率不太敏感，广泛的掩蔽比率（40-80%）效果很好。图5中所有的微调结果都比从头开始训练的结果好（82.5%）。

