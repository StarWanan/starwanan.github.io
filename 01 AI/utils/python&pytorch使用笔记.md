# pytorch

## å‚æ•° & å‘½ä»¤è¡Œ & è¾…åŠ© 

### logger

[loggeræ¨¡å—è§£é‡Š â€”â€” CSDN](https://blog.csdn.net/liming89/article/details/109609557)
[loggerä½¿ç”¨æ¡ˆä¾‹](https://vimsky.com/examples/detail/python-method-utils.logger.setup_logger.html)

loggingæ¨¡å—æ˜¯Pythonå†…ç½®çš„æ ‡å‡†æ¨¡å—ï¼Œä¸»è¦ç”¨äºŽè¾“å‡ºè¿è¡Œæ—¥å¿—ï¼Œå¯ä»¥è®¾ç½®è¾“å‡ºæ—¥å¿—çš„ç­‰çº§ã€æ—¥å¿—ä¿å­˜è·¯å¾„ã€æ—¥å¿—æ–‡ä»¶å›žæ»šç­‰



### yacs.config

[yacsä½¿ç”¨ â€”â€” çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/366289700)

yacsåº“ï¼Œç”¨äºŽä¸ºä¸€ä¸ªç³»ç»Ÿæž„å»ºconfigæ–‡ä»¶

éœ€è¦åˆ›å»º`CN()`è¿™ä¸ªä½œä¸ºå®¹å™¨æ¥è£…è½½æˆ‘ä»¬çš„å‚æ•°ï¼Œè¿™ä¸ªå®¹å™¨å¯ä»¥åµŒå¥—

### æ‰‹åŠ¨å¢žåŠ å‚æ•°
```python
import argparse

parser = argparse.ArgumentParser()
parser.add_argument('--device', default='0,1', type=str, help='è®¾ç½®ä½¿ç”¨å“ªäº›æ˜¾å¡')
parser.add_argument('--no_cuda', action='store_true', help='ä¸é€‚ç”¨GPUè¿›è¡Œè®­ç»ƒ')
args = parser.parse_args()
print(args)
```

å‘½ä»¤è¡Œï¼š`python test.py --device 0 --no_cuda`

jupyterï¼š

1. é¦–å…ˆä»£ç ç¬¬6è¡Œæ”¹æˆï¼š`args = parser.parse_args(args=['--device', '0',  '--no_cuda'])`,ä¼ å‚æ”¹æˆ**åˆ—è¡¨å½¢å¼**
2. è¿è¡Œjupyterå•å…ƒ





## è®¾å¤‡ç›¸å…³

### torch.cuda.synchronize()

ç­‰å¾…å½“å‰è®¾å¤‡ä¸Šæ‰€æœ‰æµä¸­çš„æ‰€æœ‰æ ¸å¿ƒå®Œæˆã€‚

ðŸŒ°ï¼šæµ‹è¯•æ—¶é—´çš„ä»£ç 

```python
# code 1
start = time.time()
result = model(input)
end = time.time()

# code 2
torch.cuda.synchronize()
start = time.time()
result = model(input)
torch.cuda.synchronize()
end = time.time()

# code 3
start = time.time()
result = model(input)
print(result)
end = time.time()
```

ä»£ç 2æ˜¯æ­£ç¡®çš„ã€‚å› ä¸ºåœ¨pytorché‡Œé¢ï¼Œç¨‹åºçš„æ‰§è¡Œéƒ½æ˜¯å¼‚æ­¥çš„ã€‚
å¦‚æžœé‡‡ç”¨ä»£ç 1ï¼Œæµ‹è¯•çš„æ—¶é—´ä¼šå¾ˆçŸ­ï¼Œå› ä¸ºæ‰§è¡Œå®Œend=time.time()ç¨‹åºå°±é€€å‡ºäº†ï¼ŒåŽå°çš„cuä¹Ÿå› ä¸ºpythonçš„é€€å‡ºé€€å‡ºäº†ã€‚
å¦‚æžœé‡‡ç”¨ä»£ç 2ï¼Œä»£ç ä¼šåŒæ­¥cuçš„æ“ä½œï¼Œç­‰å¾…gpuä¸Šçš„æ“ä½œéƒ½å®Œæˆäº†å†ç»§ç»­æˆå½¢end = time.time()

ä»£ç 3å’Œä»£ç 2çš„æ—¶é—´æ˜¯ç±»ä¼¼çš„ã€‚
å› ä¸ºä»£ç 3ä¼šç­‰å¾…gpuä¸Šçš„ç»“æžœæ‰§è¡Œå®Œä¼ ç»™printå‡½æ•°ï¼Œæ‰€ä»¥æ—¶é—´å°±å’Œä»£ç 2åŒæ­¥çš„æ“ä½œçš„æ—¶é—´åŸºæœ¬ä¸Šæ˜¯ä¸€è‡´çš„äº†ã€‚
å°†print(result)æ¢æˆresult.cpu()ç»“æžœæ˜¯ä¸€è‡´çš„ã€‚



## æ•°æ®åŠ è½½

### å›¾åƒæ•°æ®å˜æ¢

transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])

Normalizeæ˜¯æŠŠå›¾åƒæ•°æ®ä»Ž[0,1]å˜æˆ[-1,1]ï¼Œå˜æ¢å…¬å¼æ˜¯image=(image-mean)/stdï¼Œé‚£ä¹ˆå…¶ä¸­çš„å‚æ•°å°±åˆ†åˆ«æ˜¯ä¸‰ä¸ªé€šé“çš„meanå’Œstdï¼Œè¿™ä¸ªå‡å€¼å’Œæ ‡å‡†å·®éœ€è¦è‡ªå·±è®¡ç®—ï¼ŒèŒƒå›´å°±æ˜¯è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ‰€æœ‰å›¾åƒã€‚


### Sampler
[Pytorch Samplerè¯¦è§£ - cnblog](https://www.cnblogs.com/marsggbo/p/11541054.html)
  
æ‰€æœ‰çš„é‡‡æ ·å™¨éƒ½ç»§æ‰¿è‡ª`Sampler`è¿™ä¸ªç±»,å¯ä»¥çœ‹åˆ°ä¸»è¦æœ‰ä¸‰ç§æ–¹æ³•ï¼šåˆ†åˆ«æ˜¯ï¼š
-   `__init__`: è¿™ä¸ªå¾ˆå¥½ç†è§£ï¼Œå°±æ˜¯åˆå§‹åŒ–
-   `__iter__`: è¿™ä¸ªæ˜¯ç”¨æ¥äº§ç”Ÿè¿­ä»£ç´¢å¼•å€¼çš„ï¼Œä¹Ÿå°±æ˜¯æŒ‡å®šæ¯ä¸ªstepéœ€è¦è¯»å–å“ªäº›æ•°æ®
-   `__len__`: è¿™ä¸ªæ˜¯ç”¨æ¥è¿”å›žæ¯æ¬¡è¿­ä»£å™¨çš„é•¿åº¦

```python
class Sampler(object):
    r"""Base class for all Samplers.
    Every Sampler subclass has to provide an __iter__ method, providing a way
    to iterate over indices of dataset elements, and a __len__ method that
    returns the length of the returned iterators.
    """
    # ä¸€ä¸ª è¿­ä»£å™¨ åŸºç±»
    def __init__(self, data_source):
        pass

    def __iter__(self):
        raise NotImplementedError

    def __len__(self):
        raise NotImplementedError
```


### DataSetã€DataLoader

[CSDNåŽŸæ–‡é“¾æŽ¥](https://blog.csdn.net/weixin_42468475/article/details/108714940)
[collate_fnå‚æ•°ä½¿ç”¨è¯¦è§£ â€”â€” çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/361830892)
[num_workså‚æ•° â€”â€” CSDN](https://blog.csdn.net/qq_24407657/article/details/103992170)

---

åŠ è½½ä¸€ä¸ªbatchçš„æ•°æ®è¿™ä¸€æ­¥éœ€è¦ä½¿ç”¨ä¸€ä¸ª`torch.utils.data.DataLoader`å¯¹è±¡ï¼Œå¹¶ä¸”DataLoaderæ˜¯ä¸€ä¸ªåŸºäºŽæŸä¸ªdatasetçš„iterableï¼Œè¿™ä¸ªiterableæ¯æ¬¡ä»Ždatasetä¸­åŸºäºŽæŸç§é‡‡æ ·åŽŸåˆ™å–å‡ºä¸€ä¸ªbatchçš„æ•°æ®ã€‚
ä¹Ÿå¯ä»¥è¿™æ ·è¯´ï¼šTorchä¸­å¯ä»¥åˆ›å»ºä¸€ä¸ªtorch.utils.data.==Dataset==å¯¹è±¡ï¼Œå¹¶ä¸Žtorch.utils.data.==DataLoader==ä¸€èµ·ä½¿ç”¨ï¼Œåœ¨è®­ç»ƒæ¨¡åž‹æ—¶ä¸æ–­ä¸ºæ¨¡åž‹æä¾›æ•°æ®ã€‚

**torch.utils.data.DataLoader**

å®šä¹‰ï¼šData loader. Combines a dataset and a sampler, and provides an iterable over the given dataset.
æž„é€ å‡½æ•°:
```python
torch.utils.data.DataLoader(dataset, 
							batch_size=1, 
							shuffle=False, 
							sampler=None,
							batch_sampler=None, num_workers=0, collate_fn=None,
							pin_memory=False, drop_last=False, timeout=0,
							worker_init_fn=None)
```
- dataset: æŠ½è±¡ç±»,åŒ…å«ä¸¤ç§ç±»åž‹
	- `map-style datasets `
	- `iterable-style datasets`
- batch_size : æ¯ä¸€æ¬¡æŠ½æ ·çš„batch-sizeå¤§å°
- shuffle : Trueåˆ™éšæœºæ‰“ä¹±æ•°æ®
- Num_worksï¼šå°†batchåŠ è½½è¿›RAMçš„è¿›ç¨‹æ•°ã€‚å†…å­˜å¼€é”€å¤§ï¼ŒCPUè´Ÿæ‹…å¤§ã€‚å¯èƒ½ä¹‹åŽå‡ æ¬¡è¿­ä»£çš„æ•°æ®åœ¨æœ¬æ¬¡è¿­ä»£çš„æ—¶å€™å·²ç»åŠ è½½è¿›å†…å­˜ã€‚
- collate_fnï¼šå¦‚ä½•å–æ ·æœ¬çš„ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰è‡ªå·±çš„å‡½æ•°æ¥å‡†ç¡®åœ°å®žçŽ°æƒ³è¦çš„åŠŸèƒ½ã€‚
- drop_lastï¼šå‘Šè¯‰å¦‚ä½•å¤„ç†æ•°æ®é›†é•¿åº¦é™¤äºŽbatch_sizeä½™ä¸‹çš„æ•°æ®ã€‚Trueå°±æŠ›å¼ƒï¼Œå¦åˆ™ä¿ç•™ã€‚

**Map-style datasets**

æ˜¯ä¸€ä¸ªç±»ï¼Œè¦æ±‚æœ‰ `__getitem__()`and`__len__()`è¿™ä¸¤ä¸ªæž„é€ å‡½æ•°ï¼Œä»£è¡¨ä¸€ä¸ªä»Žç´¢å¼•æ˜ å°„åˆ°æ•°æ®æ ·æœ¬ã€‚
- `__getitem__()`: æ ¹æ®ç´¢å¼•indexéåŽ†æ•°æ®
- `__len__()`: è¿”å›žæ•°æ®é›†çš„é•¿åº¦
- å¯ç¼–å†™ç‹¬ç«‹çš„æ•°æ®å¤„ç†å‡½æ•°
	- åœ¨ `__getitem()__` å‡½æ•°ä¸­è¿›è¡Œè°ƒç”¨
	- ç›´æŽ¥å°†æ•°æ®å¤„ç†å‡½æ•°å†™åœ¨ `__getitem()__` æˆ–è€… `__init()__` å‡½æ•°ä¸­ï¼Œä½†æ˜¯`__getitem()__`
	å¿…é¡»æ ¹æ®==index==è¿”å›žå“åº”çš„å€¼ï¼Œè¯¥å€¼ä¼šé€šè¿‡indexä¼ åˆ°dataloaderä¸­è¿›è¡ŒåŽç»­çš„batchæ‰¹å¤„ç†ã€‚

åŸºæœ¬éœ€è¦æ»¡è¶³ï¼š
```python
def __getitem__(self, index):
    return self.src[index], self.trg[index]

def __len__(self):
	return len(self.src)  
```



`getitem()`æ–¹æ³•ç”¨æ¥ä»Ždatasetsä¸­è¯»å–ä¸€æ¡æ•°æ®ï¼Œè¿™æ¡æ•°æ®åŒ…å«è®­ç»ƒ**å›¾ç‰‡**ï¼ˆä»¥å›¾ç‰‡ä¸¾ä¾‹ï¼‰å’Œ**æ ‡ç­¾**ï¼Œå‚æ•°indexè¡¨ç¤ºå›¾ç‰‡å’Œæ ‡ç­¾åœ¨æ€»æ•°æ®é›†ä¸­çš„Indexã€‚

`len()`æ–¹æ³•è¿”å›žæ•°æ®é›†çš„æ€»é•¿åº¦ï¼ˆè®­ç»ƒé›†çš„æ€»æ•°ï¼‰ã€‚

**å®žçŽ° MyDatasets ç±»**

1. ç®€å•ç›´ç™½

æŠŠ x å’Œ label åˆ†åˆ«è£…å…¥ä¸¤ä¸ªåˆ—è¡¨ self.src å’Œ self.trg ï¼Œç„¶åŽé€šè¿‡ getitem(self, idex) è¿”å›žå¯¹åº”å…ƒç´ 
```python
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader
 
class My_dataset(Dataset):
    def __init__(self):
        super().__init__()
        ## ä½¿ç”¨sinå‡½æ•°è¿”å›ž10000ä¸ªæ—¶é—´åºåˆ—,å¦‚æžœä¸è‡ªå·±æž„é€ æ•°æ®ï¼Œå°±ä½¿ç”¨numpy,pandasç­‰è¯»å–è‡ªå·±çš„æ•°æ®ä¸ºxå³å¯ã€‚
        ## ä»¥ä¸‹æ•°æ®ç»„ç»‡è¿™å—æ—¢å¯ä»¥æ”¾åœ¨initæ–¹æ³•é‡Œï¼Œä¹Ÿå¯ä»¥æ”¾åœ¨getitemæ–¹æ³•é‡Œ
        self.x = torch.randn(1000,3)
        self.y = self.x.sum(axis=1)
        self.src,  self.trg = [], []
        for i in range(1000):
            self.src.append(self.x[i])
            self.trg.append(self.y[i])
    
           
    def __getitem__(self, index):
        return self.src[index], self.trg[index]

    def __len__(self):
        return len(self.src) 
        
 ## æˆ–è€…return len(self.trg), srcå’Œtrgé•¿åº¦ä¸€æ ·
 
data_train = My_dataset()
data_test = My_dataset()
data_loader_train = DataLoader(data_train, batch_size=5, shuffle=False)
data_loader_test = DataLoader(data_test, batch_size=5, shuffle=False)
## i_batchçš„å¤šå°‘æ ¹æ®batch sizeå’Œdef __len__(self)è¿”å›žçš„é•¿åº¦ç¡®å®š
## batch_dataè¿”å›žçš„å€¼æ ¹æ®def __getitem__(self, index)æ¥ç¡®å®š
## å¯¹è®­ç»ƒé›†ï¼š(ä¸å¤ªæ¸…æ¥šenumerateè¿”å›žä»€ä¹ˆçš„æ—¶å€™å°±å¤šprintè¯•è¯•)
for i_batch, batch_data in enumerate(data_loader_train):
    print(i_batch)  ## æ‰“å°batchç¼–å·
    print(batch_data[0])  ## æ‰“å°è¯¥batché‡Œé¢src
    print(batch_data[1])  ## æ‰“å°è¯¥batché‡Œé¢trg
## å¯¹æµ‹è¯•é›†ï¼šï¼ˆä¸‹é¢çš„è¯­å¥ä¹Ÿå¯ä»¥ï¼‰
for i_batch, (src, trg) in enumerate(data_loader_test):
    print(i_batch)  ## æ‰“å°batchç¼–å·
    print(src)  ## æ‰“å°è¯¥batché‡Œé¢srcçš„å°ºå¯¸
    print(trg)  ## æ‰“å°è¯¥batché‡Œé¢trgçš„å°ºå¯¸    
```

ç”Ÿæˆçš„data_trainå¯ä»¥é€šè¿‡ `data_train[xxx]`ç›´æŽ¥ç´¢å¼•æŸä¸ªå…ƒç´ ï¼Œæˆ–è€…é€šè¿‡`next(iter(data_train))` å¾—åˆ°ä¸€æ¡æ¡çš„æ•°æ®ã€‚

2. å€ŸåŠ©TensorDatasetå°†æ•°æ®åŒ…è£…æˆdataset
```python
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader, TensorDataset
 
src = torch.sin(torch.arange(1, 1000, 0.1))
trg = torch.cos(torch.arange(1, 1000, 0.1))
 
data = TensorDataset(src, trg)
data_loader = DataLoader(data, batch_size=5, shuffle=False)
for i_batch, batch_data in enumerate(data_loader):
    print(i_batch)  ## æ‰“å°batchç¼–å·
    print(batch_data[0].size())  ## æ‰“å°è¯¥batché‡Œé¢src
    print(batch_data[1].size())  ## æ‰“å°è¯¥batché‡Œé¢trg
```

3. åœ°å€è¯»å–ï¼Œç”Ÿæˆæ•°æ®çš„è·¯å¾„ txt æ–‡ä»¶
```python
import os

from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import matplotlib.image as mpimg



## å¯¹æ‰€æœ‰å›¾ç‰‡ç”Ÿæˆpath-label map.txt è¿™ä¸ªç¨‹åºå¯æ ¹æ®å®žé™…éœ€è¦é€‚å½“ä¿®æ”¹
def generate_map(root_dir):
	##å¾—åˆ°å½“å‰ç»å¯¹è·¯å¾„
    current_path = os.path.abspath('.')
    ##os.path.dirname()å‘å‰é€€ä¸€ä¸ªè·¯å¾„
    father_path = os.path.abspath(os.path.dirname(current_path) + os.path.sep + ".")

    with open(root_dir + 'map.txt', 'w') as wfp:
        for idx in range(10):
            subdir = os.path.join(root_dir, '%d/' % idx)
            for file_name in os.listdir(subdir):
                abs_name = os.path.join(father_path, subdir, file_name)
                ## linux_abs_name = abs_name.replace("\\", '/')
                wfp.write('{file_dir} {label}\n'.format(file_dir=linux_abs_name, label=idx))

## å®žçŽ°MyDatasetsç±»
class MyDatasets(Dataset):

    def __init__(self, dir):
        ## èŽ·å–æ•°æ®å­˜æ”¾çš„dir
        ## ä¾‹å¦‚d:/images/
        self.data_dir = dir
        ## ç”¨äºŽå­˜æ”¾(image,label) tupleçš„list,å­˜æ”¾çš„æ•°æ®ä¾‹å¦‚(d:/image/1.png,4)
        self.image_target_list = []
        ## ä»Ždir--labelçš„mapæ–‡ä»¶ä¸­å°†æ‰€æœ‰çš„tupleå¯¹è¯»å–åˆ°image_target_listä¸­
        ## map.txtä¸­å…¨éƒ¨å­˜æ”¾çš„æ˜¯d:/.../image_data/1/3.jpg 1 è·¯å¾„æœ€å¥½æ˜¯ç»å¯¹è·¯å¾„
        with open(os.path.join(dir, 'map.txt'), 'r') as fp:
            content = fp.readlines()
            ##s.rstrip()åˆ é™¤å­—ç¬¦ä¸²æœ«å°¾æŒ‡å®šå­—ç¬¦ï¼ˆé»˜è®¤æ˜¯å­—ç¬¦ï¼‰
            ## å¾—åˆ° [['d:/.../image_data/1/3.jpg', '1'], ...,]
            str_list = [s.rstrip().split() for s in content]
            ## å°†æ‰€æœ‰å›¾ç‰‡çš„dir--labelå¯¹éƒ½æ”¾å…¥åˆ—è¡¨ï¼Œå¦‚æžœè¦æ‰§è¡Œå¤šä¸ªepochï¼Œå¯ä»¥åœ¨è¿™é‡Œå¤šå¤åˆ¶å‡ éï¼Œç„¶åŽç»Ÿä¸€shuffleæ¯”è¾ƒå¥½
            self.image_target_list = [(x[0], int(x[1])) for x in str_list]

    def __getitem__(self, index):
        image_label_pair = self.image_target_list[index]
        ## æŒ‰pathè¯»å–å›¾ç‰‡æ•°æ®ï¼Œå¹¶è½¬æ¢ä¸ºå›¾ç‰‡æ ¼å¼ä¾‹å¦‚[3,32,32]
        ## å¯ä»¥ç”¨åˆ«çš„ä»£æ›¿
        img = mpimg.imread(image_label_pair[0])
        return img, image_label_pair[1]

    def __len__(self):
        return len(self.image_target_list)


if __name__ == '__main__':
    ## ç”Ÿæˆmap.txt
    ## generate_map('train/')

    train_loader = DataLoader(MyDatasets('train/'), batch_size=128, shuffle=True)

    for step in range(20000):
        for idx, (img, label) in enumerate(train_loader):
            print(img.shape)
            print(label.shape)
```



### Sampler DataSet DataLoaderä¹‹é—´çš„å…³ç³»
> [ä¸€æ–‡å¼„æ‡‚Pytorchçš„DataLoader, DataSet, Samplerä¹‹é—´çš„å…³ç³» - cnblog](https://www.cnblogs.com/marsggbo/p/11308889.html)
> [è¿„ä»Šä¸ºæ­¢æœ€ç»†è‡´çš„DataSetå’ŒDataloaderåŠ è½½æ­¥éª¤ - çŸ¥ä¹Ž](https://zhuanlan.zhihu.com/p/381224748)


![image.png](https://s1.vika.cn/space/2023/02/15/d8e3873e2a0e4ad491191cfc498cd743)

![image.png](https://s1.vika.cn/space/2023/02/15/8739a8e8fc454b799e25aaf242a27a35)



dataloader æºç ï¼š
```python
class DataLoader(object):
    def __init__(self, dataset, batch_size=1, shuffle=False, sampler=None,
				 batch_sampler=None, num_workers=0, collate_fn=default_collate,
				 pin_memory=False, drop_last=False, timeout=0,
				 worker_init_fn=None)
```
æœ‰ä¸¤ä¸ªå’Œsamplerç›¸å…³çš„å‚æ•°ï¼š
- `sampler`: ç”Ÿæˆä¸€ç³»åˆ—çš„ index
- `batch_sampler`: å°†samplerç”Ÿæˆçš„ indices æ‰“åŒ…åˆ†ç»„

éœ€è¦æ³¨æ„çš„æ˜¯DataLoaderçš„éƒ¨åˆ†åˆå§‹åŒ–å‚æ•°ä¹‹é—´å­˜åœ¨äº’æ–¥å…³ç³»ï¼Œå¯ä»¥é€šè¿‡é˜…è¯»[æºç ](https://github.com/pytorch/pytorch/blob/0b868b19063645afed59d6d49aff1e43d1665b88/torch/utils/data/dataloader.py#L157-L182)æ›´æ·±åœ°ç†è§£ï¼Œè¿™é‡Œåªåšæ€»ç»“ï¼š
- å¦‚æžœä½ è‡ªå®šä¹‰äº†`batch_sampler`,é‚£ä¹ˆè¿™äº›å‚æ•°éƒ½å¿…é¡»ä½¿ç”¨é»˜è®¤å€¼ï¼š`batch_size`,Â `shuffle`,`sampler`,`drop_last`.
- å¦‚æžœä½ è‡ªå®šä¹‰äº†`sampler`ï¼Œé‚£ä¹ˆ`shuffle`éœ€è¦è®¾ç½®ä¸º`False`
- å¦‚æžœ`sampler`å’Œ`batch_sampler`éƒ½ä¸º`None`,é‚£ä¹ˆ`batch_sampler`ä½¿ç”¨Pytorchå·²ç»å®žçŽ°å¥½çš„`BatchSampler`,è€Œ`sampler`åˆ†ä¸¤ç§æƒ…å†µï¼š
    - è‹¥`shuffle=True`,åˆ™`sampler=RandomSampler(dataset)`
    - è‹¥`shuffle=False`,åˆ™`sampler=SequentialSampler(dataset)`

Sampler æºç ï¼š
```python
class Sampler(object):
    r"""Base class for all Samplers.
    Every Sampler subclass has to provide an :meth:`__iter__` method, providing a
    way to iterate over indices of dataset elements, and a :meth:`__len__` method
    that returns the length of the returned iterators.
    .. note:: The :meth:`__len__` method isn't strictly required by
              :class:`~torch.utils.data.DataLoader`, but is expected in any
              calculation involving the length of a :class:`~torch.utils.data.DataLoader`.
    """

    def __init__(self, data_source):
        pass

    def __iter__(self):
        raise NotImplementedError
		
    def __len__(self):
        return len(self.data_source)
```

DataSet:
```python
class Dataset(object):
	def __init__(self):
		...
		
	def __getitem__(self, index):
		return ...
	
	def __len__(self):
		return ...
```

`__next__`:DataLoaderå¯¹æ•°æ®çš„è¯»å–å…¶å®žå°±æ˜¯ç”¨äº†forå¾ªçŽ¯æ¥éåŽ†æ•°æ®
```python
class DataLoader(object): 
    ... 
     
    def __next__(self): 
        if self.num_workers == 0:   
            indices = next(self.sample_iter)  
            batch = self.collate_fn([self.dataset[i] for i in indices]) # this line 
            if self.pin_memory: 
                batch = _utils.pin_memory.pin_memory_batch(batch) 
            return batch
```

åˆå¹¶æˆä¸€ä¸ªbatchçš„æ“ä½œï¼š
```python
class DataLoader(object): 
    ... 
     
    def __next__(self): 
        if self.num_workers == 0:   
            indices = next(self.sample_iter)  
            batch = self.collate_fn([self.dataset[i] for i in indices]) # this line 
            if self.pin_memory: 
                batch = _utils.pin_memory.pin_memory_batch(batch) 
            return batch
```
- `indices`: è¡¨ç¤ºæ¯ä¸€ä¸ªiterationï¼Œsamplerè¿”å›žçš„indicesï¼Œå³ä¸€ä¸ªbatch sizeå¤§å°çš„ç´¢å¼•åˆ—è¡¨
- `self.dataset[i]`: è¿™é‡Œå°±æ˜¯å¯¹ç¬¬iä¸ªæ•°æ®è¿›è¡Œè¯»å–æ“ä½œï¼Œä¸€èˆ¬æ¥è¯´`self.dataset[i]=(img, label)`
çœ‹åˆ°è¿™ä¸éš¾çŒœå‡º`collate_fn`çš„ä½œç”¨å°±æ˜¯å°†ä¸€ä¸ªbatchçš„æ•°æ®è¿›è¡Œåˆå¹¶æ“ä½œã€‚é»˜è®¤çš„`collate_fn`æ˜¯å°†imgå’Œlabelåˆ†åˆ«åˆå¹¶æˆimgså’Œlabelsï¼Œæ‰€ä»¥å¦‚æžœä½ çš„`__getitem__`æ–¹æ³•åªæ˜¯è¿”å›žÂ `img, label`,é‚£ä¹ˆä½ å¯ä»¥ä½¿ç”¨é»˜è®¤çš„`collate_fn`æ–¹æ³•ï¼Œä½†æ˜¯å¦‚æžœä½ æ¯æ¬¡è¯»å–çš„æ•°æ®æœ‰`img, box, label`ç­‰ç­‰ï¼Œé‚£ä¹ˆä½ å°±éœ€è¦è‡ªå®šä¹‰`collate_fn`æ¥å°†å¯¹åº”çš„æ•°æ®åˆå¹¶æˆä¸€ä¸ªbatchæ•°æ®ï¼Œè¿™æ ·æ–¹ä¾¿åŽç»­çš„è®­ç»ƒæ­¥éª¤ã€‚


## ç½‘ç»œæ¨¡åž‹

### apply åˆå§‹åŒ–å‚æ•°
[pytorchç³»åˆ—10 --- å¦‚ä½•è‡ªå®šä¹‰å‚æ•°åˆå§‹åŒ–æ–¹å¼ ï¼Œapply()](https://blog.csdn.net/dss_dssssd/article/details/83990511)


### nn.Conv2d
[Pytorchçš„nn.Conv2dï¼ˆï¼‰è¯¦è§£_é£Žé›ªå¤œå½’äººoçš„åšå®¢-CSDNåšå®¢_nnæ˜¯ä»€ä¹ˆæ„æ€](https://blog.csdn.net/qq_42079689/article/details/102642610)

---

```python
class Net(nn.Module):
    def __init__(self):
        nn.Module.__init__(self)
        self.conv2d = nn.Conv2d(in_channels=3,out_channels=64,kernel_size=4,stride=2,padding=1)

    def forward(self, x):
        print(x.requires_grad)
        x = self.conv2d(x)
        return x
    
print(net.conv2d.weight)
print(net.conv2d.bias)
```


### flatten
[CNNçš„Flattenæ“ä½œ](https://cloud.tencent.com/developer/article/1620842)

---


- `torch.flatten(Python function, in torch)`
- `torch.nn.Flatten(Python class, in torch.nn)`
- `torch.Tensor.flatten(Python methodm in torch.nn.Tensor)`

#### torch.flatten
```python
#å±•å¹³ä¸€ä¸ªè¿žç»­èŒƒå›´çš„ç»´åº¦ï¼Œè¾“å‡ºç±»åž‹ä¸ºTensor
torch.flatten(input, start_dim=0, end_dim=-1) â†’ Tensor
# Parametersï¼šinput (Tensor) â€“ è¾“å…¥ä¸ºTensor
# start_dim (int) â€“ å±•å¹³çš„å¼€å§‹ç»´åº¦
# end_dim (int) â€“ å±•å¹³çš„æœ€åŽç»´åº¦

#example
#ä¸€ä¸ª3x2x2çš„ä¸‰ç»´å¼ é‡
>>> t = torch.tensor([[[1, 2], [3, 4]],
                      [[5, 6], [7, 8]],
	                  [[9, 10],[11, 12]]])
#å½“å¼€å§‹ç»´åº¦ä¸º0ï¼Œæœ€åŽç»´åº¦ä¸º-1ï¼Œå±•å¼€ä¸ºä¸€ç»´
>>> torch.flatten(t)
tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])
#å½“å¼€å§‹ç»´åº¦ä¸º0ï¼Œæœ€åŽç»´åº¦ä¸º-1ï¼Œå±•å¼€ä¸º3x4ï¼Œä¹Ÿå°±æ˜¯è¯´ç¬¬ä¸€ç»´åº¦ä¸å˜ï¼ŒåŽé¢çš„åŽ‹ç¼©
>>> torch.flatten(t, start_dim=1)
tensor([[ 1,  2,  3,  4],
        [ 5,  6,  7,  8],
        [ 9, 10, 11, 12]])
>>> torch.flatten(t, start_dim=1).size()
torch.Size([3, 4])
#ä¸‹é¢çš„å’Œä¸Šé¢è¿›è¡Œå¯¹æ¯”åº”è¯¥å°±èƒ½çœ‹å‡ºæ˜¯ï¼Œå½“é”å®šæœ€åŽçš„ç»´åº¦çš„æ—¶å€™
#å‰é¢çš„å°±ä¼šåˆå¹¶
>>> torch.flatten(t, start_dim=0, end_dim=1)
tensor([[ 1,  2],
        [ 3,  4],
        [ 5,  6],
        [ 7,  8],
        [ 9, 10],
        [11, 12]])
>>> torch.flatten(t, start_dim=0, end_dim=1).size()
torch.Size([6, 2])

```


#### torch.nn.Flatten()
torch.nn.Flatten()å¯ä»¥æ˜¯Sequentialæ¨¡åž‹çš„ä¸€å±‚

pytorchä¸­çš„ torch.nn.Flatten ç±»å’Œ torch.Tensor.flatten æ–¹æ³•å…¶å®žéƒ½æ˜¯åŸºäºŽ torch.flatten å‡½æ•°å®žçŽ°çš„ã€‚


### nn.Sequential
[pytorchç³»åˆ—7 -----nn.Sequentialè®²è§£](https://blog.csdn.net/dss_dssssd/article/details/82980222)

---
nn.Sequential
A sequential container. Modules will be added to it in the order they are passed in the constructor. Alternatively, an ordered dict of modules can also be passed in.

ä¸€ä¸ªæœ‰åºçš„==å®¹å™¨==ï¼Œç¥žç»ç½‘ç»œæ¨¡å—å°†æŒ‰ç…§åœ¨ä¼ å…¥æž„é€ å™¨çš„é¡ºåºä¾æ¬¡è¢«æ·»åŠ åˆ°è®¡ç®—å›¾ä¸­æ‰§è¡Œï¼ŒåŒæ—¶ä»¥ç¥žç»ç½‘ç»œæ¨¡å—ä¸ºå…ƒç´ çš„æœ‰åºå­—å…¸ä¹Ÿå¯ä»¥ä½œä¸ºä¼ å…¥å‚æ•°ã€‚

```python
# Example of using Sequential
model = nn.Sequential(
		  nn.Conv2d(1,20,5),
		  nn.ReLU(),
		  nn.Conv2d(20,64,5),
		  nn.ReLU()
		)

# Example of using Sequential with OrderedDict
model = nn.Sequential(OrderedDict([
		  ('conv1', nn.Conv2d(1,20,5)),
		  ('relu1', nn.ReLU()),
		  ('conv2', nn.Conv2d(20,64,5)),
		  ('relu2', nn.ReLU())
		]))

```



## train & eval

### with torch.no_grad()

> å‚è€ƒï¼šhttps://blog.csdn.net/sazass/article/details/116668755

ä½œç”¨ï¼šåœ¨è¯¥æ¨¡å—ä¸‹ï¼Œæ‰€æœ‰è®¡ç®—å¾—å‡ºçš„tensorçš„requires_gradéƒ½è‡ªåŠ¨è®¾ç½®ä¸ºFalseã€‚å½“requires_gradè®¾ç½®ä¸ºFalseæ—¶,åå‘ä¼ æ’­æ—¶å°±ä¸ä¼šè‡ªåŠ¨æ±‚å¯¼äº†ï¼Œå› æ­¤å¤§å¤§èŠ‚çº¦äº†æ˜¾å­˜æˆ–è€…è¯´å†…å­˜ã€‚



### nn.DataParallel
[Pytorchçš„nn.DataParallel - çŸ¥ä¹Ž (zhihu.com)](https://zhuanlan.zhihu.com/p/102697821)
å¤šå¡å¹¶è¡Œçš„å‘½ä»¤ï¼Œä»¥åŠå¯èƒ½å‡ºçš„é”™è¯¯

---

å½“è¿­ä»£æ¬¡æ•°æˆ–è€…epochè¶³å¤Ÿå¤§çš„æ—¶å€™ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šä½¿ç”¨nn.DataParallelå‡½æ•°æ¥ç”¨å¤šä¸ªGPUæ¥åŠ é€Ÿè®­ç»ƒ

````python
CLASS torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)
````

moduleå³è¡¨ç¤ºä½ å®šä¹‰çš„æ¨¡åž‹
device_idsè¡¨ç¤ºä½ è®­ç»ƒçš„device
output_deviceè¿™ä¸ªå‚æ•°è¡¨ç¤ºè¾“å‡ºç»“æžœçš„device


### nn.Parameter()
[PyTorchä¸­çš„torch.nn.Parameter() è¯¦è§£_Adenialzzçš„åšå®¢-CSDNåšå®¢](https://blog.csdn.net/weixin_44966641/article/details/118730730)

---

é¦–å…ˆå¯ä»¥æŠŠè¿™ä¸ªå‡½æ•°ç†è§£ä¸ºç±»åž‹è½¬æ¢å‡½æ•°ï¼Œå°†ä¸€ä¸ªä¸å¯è®­ç»ƒçš„ç±»åž‹Tensorè½¬æ¢æˆå¯ä»¥è®­ç»ƒçš„ç±»åž‹parameterå¹¶å°†è¿™ä¸ªparameterç»‘å®šåˆ°è¿™ä¸ªmoduleé‡Œé¢(net.parameter()ä¸­å°±æœ‰è¿™ä¸ªç»‘å®šçš„parameterï¼Œæ‰€ä»¥åœ¨å‚æ•°ä¼˜åŒ–çš„æ—¶å€™å¯ä»¥è¿›è¡Œä¼˜åŒ–çš„)ï¼Œæ‰€ä»¥ç»è¿‡ç±»åž‹è½¬æ¢è¿™ä¸ªself.vå˜æˆäº†æ¨¡åž‹çš„ä¸€éƒ¨åˆ†ï¼Œæˆä¸ºäº†æ¨¡åž‹ä¸­æ ¹æ®è®­ç»ƒå¯ä»¥æ”¹åŠ¨çš„å‚æ•°äº†ã€‚ä½¿ç”¨è¿™ä¸ªå‡½æ•°çš„ç›®çš„ä¹Ÿæ˜¯æƒ³è®©æŸäº›å˜é‡åœ¨å­¦ä¹ çš„è¿‡ç¨‹ä¸­ä¸æ–­çš„ä¿®æ”¹å…¶å€¼ä»¥è¾¾åˆ°æœ€ä¼˜åŒ–ã€‚

```python
self.pos_embedding = nn.Parameter(torch.randn(1, num_patches+1, dim))
self.cls_token = nn.Parameter(torch.randn(1, 1, dim))
```



### model.train() & model.eval()
- https://blog.csdn.net/asd123pwj/article/details/123017382
è®©æ¨¡åž‹å¼€å¯è®­ç»ƒ/æµ‹è¯•æ¨¡å¼ï¼Œè®­ç»ƒæµ‹è¯•å°±å¯ä»¥ä½¿ç”¨åŒä¸€ä»½ä»£ç ã€‚



## åŠŸèƒ½å‡½æ•°

### ç”Ÿæˆå¼ é‡
`torch.rand(x,y)` ç”Ÿæˆxè¡Œyåˆ—çš„å‡åŒ€åˆ†å¸ƒçš„å¼ é‡
`torch.randn(x,y)` ç”Ÿæˆxè¡Œyåˆ—çš„æ­£æ€åˆ†å¸ƒçš„å¼ é‡

```python
A = torch.tensor([1.0,1.0],[2,2]) 
A 
#tensor([1.,1.], 
#       [2.,2.])  
```


### nn.functional.interpolate()

`torch.nn.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None, recompute_scale_factor=None)`

åŠŸèƒ½ï¼šåˆ©ç”¨æ’å€¼æ–¹æ³•ï¼Œå¯¹è¾“å…¥çš„å¼ é‡æ•°ç»„è¿›è¡Œä¸Š\ä¸‹**é‡‡æ ·**æ“ä½œï¼Œæ¢å¥è¯è¯´å°±æ˜¯ç§‘å­¦åˆç†åœ°æ”¹å˜æ•°ç»„çš„å°ºå¯¸å¤§å°ï¼Œå°½é‡ä¿æŒæ•°æ®å®Œæ•´ã€‚

`input(Tensor)`ï¼šéœ€è¦è¿›è¡Œé‡‡æ ·å¤„ç†çš„æ•°ç»„ã€‚
`size(intæˆ–åºåˆ—)`ï¼šè¾“å‡ºç©ºé—´çš„å¤§å°
`scale_factor(floatæˆ–åºåˆ—)`ï¼šç©ºé—´å¤§å°çš„ä¹˜æ•°
`mode(str)`ï¼šç”¨äºŽé‡‡æ ·çš„ç®—æ³•ã€‚'nearest'| 'linear'| 'bilinear'| 'bicubic'| 'trilinear'| 'area'ã€‚é»˜è®¤ï¼š'nearest'
`align_corners(bool)`ï¼šåœ¨å‡ ä½•ä¸Šï¼Œæˆ‘ä»¬å°†è¾“å…¥å’Œè¾“å‡ºçš„åƒç´ è§†ä¸ºæ­£æ–¹å½¢è€Œä¸æ˜¯ç‚¹ã€‚å¦‚æžœè®¾ç½®ä¸ºTrueï¼Œåˆ™è¾“å…¥å’Œè¾“å‡ºå¼ é‡æŒ‰å…¶è§’åƒç´ çš„ä¸­å¿ƒç‚¹å¯¹é½ï¼Œä¿ç•™è§’åƒç´ å¤„çš„å€¼ã€‚å¦‚æžœè®¾ç½®ä¸ºFalseï¼Œåˆ™è¾“å…¥å’Œè¾“å‡ºå¼ é‡é€šè¿‡å…¶è§’åƒç´ çš„è§’ç‚¹å¯¹é½ï¼Œå¹¶ä¸”æ’å€¼ä½¿ç”¨è¾¹ç¼˜å€¼å¡«å……ç”¨äºŽè¾¹ç•Œå¤–å€¼ï¼Œä½¿æ­¤æ“ä½œåœ¨ä¿æŒä¸å˜æ—¶ç‹¬ç«‹äºŽè¾“å…¥å¤§å°scale_factorã€‚
`recompute_scale_facto(bool)`ï¼šé‡æ–°è®¡ç®—ç”¨äºŽæ’å€¼è®¡ç®—çš„ scale_factorã€‚å½“scale_factorä½œä¸ºå‚æ•°ä¼ é€’æ—¶ï¼Œå®ƒç”¨äºŽè®¡ç®—output_sizeã€‚å¦‚æžœrecompute_scale_factorçš„Falseæˆ–æ²¡æœ‰æŒ‡å®šï¼Œä¼ å…¥çš„scale_factorå°†åœ¨æ’å€¼è®¡ç®—ä¸­ä½¿ç”¨ã€‚å¦åˆ™ï¼Œå°†æ ¹æ®ç”¨äºŽæ’å€¼è®¡ç®—çš„è¾“å‡ºå’Œè¾“å…¥å¤§å°è®¡ç®—æ–°çš„scale_factorï¼ˆå³ï¼Œå¦‚æžœè®¡ç®—çš„output_sizeæ˜¾å¼ä¼ å…¥ï¼Œåˆ™è®¡ç®—å°†ç›¸åŒ ï¼‰ã€‚æ³¨æ„å½“scale_factor æ˜¯æµ®ç‚¹æ•°ï¼Œç”±äºŽèˆå…¥å’Œç²¾åº¦é—®é¢˜ï¼Œé‡æ–°è®¡ç®—çš„ scale_factor å¯èƒ½ä¸Žä¼ å…¥çš„ä¸åŒã€‚




æ³¨æ„ï¼š

- è¾“å…¥çš„å¼ é‡æ•°ç»„é‡Œé¢çš„æ•°æ®ç±»åž‹å¿…é¡»æ˜¯floatã€‚
- è¾“å…¥çš„æ•°ç»„ç»´æ•°åªèƒ½æ˜¯3ã€4æˆ–5ï¼Œåˆ†åˆ«å¯¹åº”äºŽæ—¶é—´ã€ç©ºé—´ã€ä½“ç§¯é‡‡æ ·ã€‚
- ä¸å¯¹è¾“å…¥æ•°ç»„çš„å‰ä¸¤ä¸ªç»´åº¦(æ‰¹æ¬¡å’Œé€šé“)é‡‡æ ·ï¼Œä»Žç¬¬ä¸‰ä¸ªç»´åº¦å¾€åŽå¼€å§‹é‡‡æ ·å¤„ç†ã€‚
- è¾“å…¥çš„ç»´åº¦å½¢å¼ä¸ºï¼šæ‰¹é‡(batch_size)Ã—é€šé“(channel)Ã—[å¯é€‰æ·±åº¦]Ã—[å¯é€‰é«˜åº¦]Ã—å®½åº¦(å‰ä¸¤ä¸ªç»´åº¦å…·æœ‰ç‰¹æ®Šçš„å«ä¹‰ï¼Œä¸è¿›è¡Œé‡‡æ ·å¤„ç†)
- sizeä¸Žscale_factorä¸¤ä¸ªå‚æ•°åªèƒ½å®šä¹‰ä¸€ä¸ªï¼Œå³ä¸¤ç§é‡‡æ ·æ¨¡å¼åªèƒ½ç”¨ä¸€ä¸ªã€‚è¦ä¹ˆè®©æ•°ç»„æ”¾å¤§æˆç‰¹å®šå¤§å°ã€è¦ä¹ˆç»™å®šç‰¹å®šç³»æ•°ï¼Œæ¥ç­‰æ¯”æ”¾å¤§æ•°ç»„ã€‚
- å¦‚æžœsizeæˆ–è€…scale_factorè¾“å…¥åºåˆ—ï¼Œåˆ™å¿…é¡»åŒ¹é…è¾“å…¥çš„å¤§å°ã€‚å¦‚æžœè¾“å…¥å››ç»´ï¼Œåˆ™å®ƒä»¬çš„åºåˆ—é•¿åº¦å¿…é¡»æ˜¯2ï¼Œå¦‚æžœè¾“å…¥æ˜¯äº”ç»´ï¼Œåˆ™å®ƒä»¬çš„åºåˆ—é•¿åº¦å¿…é¡»æ˜¯3ã€‚
- å¦‚æžœsizeè¾“å…¥æ•´æ•°xï¼Œåˆ™ç›¸å½“äºŽæŠŠ3ã€4ç»´åº¦æ”¾å¤§æˆ(x,x)å¤§å°(è¾“å…¥ä»¥å››ç»´ä¸ºä¾‹ï¼Œä¸‹é¢åŒç†)ã€‚
- å¦‚æžœscale_factorè¾“å…¥æ•´æ•°xï¼Œåˆ™ç›¸å½“äºŽæŠŠ3ã€4ç»´åº¦éƒ½ç­‰æ¯”æ”¾å¤§xå€ã€‚
- modeæ˜¯â€™linearâ€™æ—¶è¾“å…¥å¿…é¡»æ˜¯3ç»´çš„ï¼›æ˜¯â€™bicubicâ€™æ—¶è¾“å…¥å¿…é¡»æ˜¯4ç»´çš„ï¼›æ˜¯â€™trilinearâ€™æ—¶è¾“å…¥å¿…é¡»æ˜¯5ç»´çš„
- å¦‚æžœalign_cornersè¢«èµ‹å€¼ï¼Œåˆ™modeå¿…é¡»æ˜¯'linear'ï¼Œ'bilinear'ï¼Œ'bicubic'æˆ–'trilinear'ä¸­çš„ä¸€ä¸ªã€‚
- æ’å€¼æ–¹æ³•ä¸åŒï¼Œç»“æžœå°±ä¸ä¸€æ ·ï¼Œéœ€è¦ç»“åˆå…·ä½“ä»»åŠ¡ï¼Œé€‰æ‹©åˆé€‚çš„æ’å€¼æ–¹æ³•ã€‚

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
ç‰ˆæƒå£°æ˜Žï¼šæœ¬æ–‡ä¸ºCSDNåšä¸»ã€Œè§†è§‰èŒæ–°ã€ã€çš„åŽŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŽŸæ–‡å‡ºå¤„é“¾æŽ¥åŠæœ¬å£°æ˜Žã€‚
åŽŸæ–‡é“¾æŽ¥ï¼šhttps://blog.csdn.net/qq_50001789/article/details/120297401

### torch.max()

`torch.max(input) â†’ Tensor`:è¿”å›žè¾“å…¥tensorä¸­æ‰€æœ‰å…ƒç´ çš„æœ€å¤§å€¼

`torch.max(input, dim, keepdim=False, out=None) -> (Tensor, LongTensor)`: æŒ‰ç»´åº¦dim è¿”å›žæœ€å¤§å€¼ï¼Œå¹¶ä¸”è¿”å›žç´¢å¼•ã€‚

```python
torch.max()[0]ï¼Œ åªè¿”å›žæœ€å¤§å€¼çš„æ¯ä¸ªæ•°

troch.max()[1]ï¼Œ åªè¿”å›žæœ€å¤§å€¼çš„æ¯ä¸ªç´¢å¼•

torch.max()[1].data åªè¿”å›žvariableä¸­çš„æ•°æ®éƒ¨åˆ†ï¼ˆåŽ»æŽ‰Variable containing:ï¼‰

torch.max()[1].data.numpy() æŠŠæ•°æ®è½¬åŒ–æˆnumpy ndarry

torch.max()[1].data.numpy().squeeze() æŠŠæ•°æ®æ¡ç›®ä¸­ç»´åº¦ä¸º1 çš„åˆ é™¤æŽ‰
```


### nn.init.normal_
`torch.nn.init.normal(tensor, mean=0, std=1)`
ä»Žç»™å®šå‡å€¼å’Œæ ‡å‡†å·®çš„æ­£æ€åˆ†å¸ƒN(mean, std)ä¸­ç”Ÿæˆå€¼ï¼Œå¡«å……è¾“å…¥çš„å¼ é‡æˆ–å˜é‡


## è®­ç»ƒé—®é¢˜
final_loss ä¼šå˜æˆnançš„æƒ…å†µï¼š lossè¿‡å¤§ï¼Œå­¦ä¹ çŽ‡ä¹Ÿå¾ˆå¤§ï¼Œå¯èƒ½ä¼šæ¢¯åº¦çˆ†ç‚¸ã€‚






# python

## ç®—æ³•
### ç¬¬ k å¤§ï¼Œç¬¬ k å°
`heapq` æ¨¡å—çš„ `nlargest()` å’Œ `nsmallest()` å‡½æ•°

```python
heapq.nlargest(n, iterable[, key])
heapq.nsmallest(n, iterable[, key])
```
ä»Žè¿­ä»£å™¨å¯¹è±¡ iterable ä¸­è¿”å›žå‰ n ä¸ªæœ€å¤§/å°çš„å…ƒç´ åˆ—è¡¨ï¼Œå…¶ä¸­å…³é”®å­—å‚æ•° key ç”¨äºŽåŒ¹é…æ˜¯å­—å…¸å¯¹è±¡çš„ iterableï¼Œç”¨äºŽæ›´å¤æ‚çš„æ•°æ®ç»“æž„ä¸­ã€‚

```python
import heapq
nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]
print(heapq.nlargest(3, nums))   
#>>> [42, 37, 23]
print(heapq.nsmallest(3, nums))  
#>>> [-4, 1, 2]
```

è¿™ä¸¤ä¸ªå‡½æ•°ä¹Ÿå¯ä»¥æŒ‰ç…§å…³é”®å­—æŽ’åº
```python
portfolio = [
    {'name': 'IBM', 'shares': 100, 'price': 91.1},
    {'name': 'AAPL', 'shares': 50, 'price': 543.22},
    {'name': 'FB', 'shares': 200, 'price': 21.09},
    {'name': 'HPQ', 'shares': 35, 'price': 31.75},
    {'name': 'YHOO', 'shares': 45, 'price': 16.35},
    {'name': 'ACME', 'shares': 75, 'price': 115.65}
]
cheap = heapq.nsmallest(3, portfolio, key=lambda s: s['price'])  #æŒ‰priceæŽ’åº
expensive = heapq.nlargest(3, portfolio, key=lambda s: s['price'])

cheap
#[{'name': 'YHOO', 'shares': 45, 'price': 16.35},
# {'name': 'FB', 'shares': 200, 'price': 21.09},
# {'name': 'HPQ', 'shares': 35, 'price': 31.75}]

expensive
#[{'name': 'AAPL', 'shares': 50, 'price': 543.22},
# {'name': 'ACME', 'shares': 75, 'price': 115.65},
# {'name': 'IBM', 'shares': 100, 'price': 91.1}]


```

### æ ¹æ®å…ƒç´ èŽ·å–ä¸‹æ ‡ä½ç½®
#### åˆ—è¡¨list
å†…ç½®æ–¹æ³•`index()`, èŽ·å– list ä¸­ç›¸åº”å…ƒç´ çš„ç¬¬ä¸€ä¸ªä½ç½®ã€‚ç¼ºç‚¹æ˜¯åªèƒ½èŽ·å¾—ä¸€ä¸ªä½ç½®
```python
a=[72, 56, 76, 84, 80, 88]
print(a.index(76))

>>> 2
```


`enumerate()`å‡½æ•°
```python
a=[72, 56, 76, 84, 80, 88]
print(list(enumerate(a)))

>>> [(0, 72), (1, 56), (2, 76), (3, 84), (4, 80), (5, 88)]

# å¾ªçŽ¯èŽ·å–ä¸‹æ ‡
print([i for i,x in enumerate(a) if x == 76])
>>> 2
```



#### æ•°ç»„numpy.array
ä½¿ç”¨ `where()`
```python
import numpy
a1 = numpy.array([5,10,15,20])

# èŽ·å–å…ƒç´ ä¿¡æ¯
info = numpy.where(vector==10)
print(info)
>>>  (array([1], dtype=int64),)

# å…ƒç´ ä¸‹æ ‡
info[0][0]
>>>  1
```

## Matplotlib

ç»˜åˆ¶å›¾ç‰‡ã€ä¿å­˜å›¾ç‰‡
```python
plt.savefig('savepic.png')#ä¿å­˜å›¾ç‰‡
plt.show()
```


## éšæœºæ•°random

éšæœºç”Ÿæˆ \[a, b\] èŒƒå›´å†…çš„æ•´æ•°
```python
import random
random.randint(a,b)
```

## numpy
[numpy | èœé¸Ÿæ•™ç¨‹](https://www.runoob.com/numpy/numpy-tutorial.html)

### Nç»´æ•°ç»„å¯¹è±¡ ndarray
#### åˆ›å»ºæ•°ç»„
##### ä»Žå·²æœ‰çš„æ•°ç»„åˆ›å»º
å‚è€ƒï¼š[èœé¸Ÿæ•™ç¨‹](https://www.runoob.com/numpy/numpy-array-from-existing-data.html)

#### arrayçš„æ¯”è¾ƒ
```python
a = np.array([1, 2, 3, 4, 5])
b = np.array([1, 2, 3, 4, 5])
d = np.array([1, 2, 3, 4, 0])
 
# åˆ¤æ–­ä¸¤ä¸ªndarrayä¸­æ‰€æœ‰å…ƒç´ éƒ½ç›¸åŒ
print(a == b)
>>> [ True  True  True  True  True]
print((a == b).all())
>>> True

# åˆ¤æ–­ä¸¤ä¸ªndarrayä¸­åŒä¸€ä½ç½®ä¸Šæ˜¯å¦æœ‰ç›¸åŒå…ƒç´ 
print(a == d)
>>> [ True  True  True  True False]
print((a == d).any())
>>> True
```

å‚è€ƒä¸Žæ‹“å±•ï¼š[arrayçš„æ¯”è¾ƒï¼Œisï¼Œis not...](https://blog.csdn.net/wangyangjingjing/article/details/81208318)

## æ•°æ®ç»“æž„

### åˆ—è¡¨list
#### åˆ¤æ–­æŸå…ƒç´ æ˜¯å¦åœ¨åˆ—è¡¨ä¸­
1. å¾ªçŽ¯æš´åŠ›åˆ¤æ–­
2. `in` å…³é”®å­—
```python
test_list = [ 1, 6, 3, 5, 3, 4 ] 
for i in test_list: 
    if(i == 4) : 
        print ("å­˜åœ¨")

if (4 in test_list): 
    print ("å­˜åœ¨") 
```

3. `set() + in`
4. `count()`
```python
test_list_set = [ 1, 6, 3, 5, 3, 4 ] 
test_list_bisect = [ 1, 6, 3, 5, 3, 4 ]
test_list_set = set(test_list_set) 
if 4 in test_list_set : 
    print ("å­˜åœ¨") 


if test_list_bisect.count(4) > 0 :
    print ("å­˜åœ¨") 
```

### å­—å…¸dict
#### ç§»é™¤ key-value å¯¹
```python
dic = {
	'a': 1,
	'b': 2,
	'c': 3
}

# del
del dic['a']

# pop()
dic.pop('a')

# items()
new_dic = {key:val for key, val in dic.items() if key != 'a'}
```


### å­—ç¬¦ä¸²
`str.lower()` å…¨éƒ¨è½¬åŒ–ä¸ºå°å†™å­—æ¯

 

## å…¶ä»–
### args & kwargs

https://zhuanlan.zhihu.com/p/50804195

args æ˜¯ arguments çš„ç¼©å†™ï¼Œè¡¨ç¤ºä½ç½®å‚æ•°ï¼›
kwargs æ˜¯ keyword arguments çš„ç¼©å†™ï¼Œè¡¨ç¤ºå…³é”®å­—å‚æ•°ã€‚

` *args` å¿…é¡»æ”¾åœ¨ `**kwargs` çš„å‰é¢ï¼Œå› ä¸ºä½ç½®å‚æ•°åœ¨å…³é”®å­—å‚æ•°çš„å‰é¢

`*args`å°±æ˜¯å°±æ˜¯ä¼ é€’ä¸€ä¸ªå¯å˜å‚æ•°**å…ƒç»„**ç»™å‡½æ•°å®žå‚

`**kwargs`åˆ™æ˜¯å°†ä¸€ä¸ªå¯å˜çš„å…³é”®å­—å‚æ•°çš„**å­—å…¸**ä¼ ç»™å‡½æ•°å®žå‚





### setattr() & getattr()

`setattr()`: è®¾ç½®å±žæ€§å€¼ï¼Œè¯¥å±žæ€§ä¸ä¸€å®šæ˜¯å­˜åœ¨çš„ã€‚

```python
setattr(object, name, value)
object -- å¯¹è±¡ã€‚
name -- å­—ç¬¦ä¸²ï¼Œå¯¹è±¡å±žæ€§ã€‚
value -- å±žæ€§å€¼ã€‚
```

```python
å¯¹å·²å­˜åœ¨çš„å±žæ€§è¿›è¡Œèµ‹å€¼ï¼š
>>>class A(object):
    bar = 1

>>> a = A()
>>> getattr(a, 'bar')          # èŽ·å–å±žæ€§ bar å€¼
1
>>> setattr(a, 'bar', 5)       # è®¾ç½®å±žæ€§ bar å€¼
>>> a.bar
5
```

```python
å¦‚æžœå±žæ€§ä¸å­˜åœ¨ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„å¯¹è±¡å±žæ€§ï¼Œå¹¶å¯¹å±žæ€§èµ‹å€¼ï¼š
class A():
    name = "runoob"
... 
>>> a = A()
>>> setattr(a, "age", 28)
>>> print(a.age)
28
>>>
```


### å®‰è£…åŒ… pip & conda
[[python pip & conda]]

### json
[[python jsonæ–‡ä»¶]]


