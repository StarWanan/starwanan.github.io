# pytorch

## å‚æ•° & å‘½ä»¤è¡Œ & è¾…åŠ© 

### logger

[loggeræ¨¡å—è§£é‡Š â€”â€” CSDN](https://blog.csdn.net/liming89/article/details/109609557)
[loggerä½¿ç”¨æ¡ˆä¾‹](https://vimsky.com/examples/detail/python-method-utils.logger.setup_logger.html)

loggingæ¨¡å—æ˜¯Pythonå†…ç½®çš„æ ‡å‡†æ¨¡å—ï¼Œä¸»è¦ç”¨äºè¾“å‡ºè¿è¡Œæ—¥å¿—ï¼Œå¯ä»¥è®¾ç½®è¾“å‡ºæ—¥å¿—çš„ç­‰çº§ã€æ—¥å¿—ä¿å­˜è·¯å¾„ã€æ—¥å¿—æ–‡ä»¶å›æ»šç­‰



### yacs.config

[yacsä½¿ç”¨ â€”â€” çŸ¥ä¹](https://zhuanlan.zhihu.com/p/366289700)

yacsåº“ï¼Œç”¨äºä¸ºä¸€ä¸ªç³»ç»Ÿæ„å»ºconfigæ–‡ä»¶

éœ€è¦åˆ›å»º`CN()`è¿™ä¸ªä½œä¸ºå®¹å™¨æ¥è£…è½½æˆ‘ä»¬çš„å‚æ•°ï¼Œè¿™ä¸ªå®¹å™¨å¯ä»¥åµŒå¥—

## è®¾å¤‡ç›¸å…³

### torch.cuda.synchronize()

ç­‰å¾…å½“å‰è®¾å¤‡ä¸Šæ‰€æœ‰æµä¸­çš„æ‰€æœ‰æ ¸å¿ƒå®Œæˆã€‚

ğŸŒ°ï¼šæµ‹è¯•æ—¶é—´çš„ä»£ç 

```python
# code 1
start = time.time()
result = model(input)
end = time.time()

# code 2
torch.cuda.synchronize()
start = time.time()
result = model(input)
torch.cuda.synchronize()
end = time.time()

# code 3
start = time.time()
result = model(input)
print(result)
end = time.time()
```

ä»£ç 2æ˜¯æ­£ç¡®çš„ã€‚å› ä¸ºåœ¨pytorché‡Œé¢ï¼Œç¨‹åºçš„æ‰§è¡Œéƒ½æ˜¯å¼‚æ­¥çš„ã€‚
å¦‚æœé‡‡ç”¨ä»£ç 1ï¼Œæµ‹è¯•çš„æ—¶é—´ä¼šå¾ˆçŸ­ï¼Œå› ä¸ºæ‰§è¡Œå®Œend=time.time()ç¨‹åºå°±é€€å‡ºäº†ï¼Œåå°çš„cuä¹Ÿå› ä¸ºpythonçš„é€€å‡ºé€€å‡ºäº†ã€‚
å¦‚æœé‡‡ç”¨ä»£ç 2ï¼Œä»£ç ä¼šåŒæ­¥cuçš„æ“ä½œï¼Œç­‰å¾…gpuä¸Šçš„æ“ä½œéƒ½å®Œæˆäº†å†ç»§ç»­æˆå½¢end = time.time()

ä»£ç 3å’Œä»£ç 2çš„æ—¶é—´æ˜¯ç±»ä¼¼çš„ã€‚
å› ä¸ºä»£ç 3ä¼šç­‰å¾…gpuä¸Šçš„ç»“æœæ‰§è¡Œå®Œä¼ ç»™printå‡½æ•°ï¼Œæ‰€ä»¥æ—¶é—´å°±å’Œä»£ç 2åŒæ­¥çš„æ“ä½œçš„æ—¶é—´åŸºæœ¬ä¸Šæ˜¯ä¸€è‡´çš„äº†ã€‚
å°†print(result)æ¢æˆresult.cpu()ç»“æœæ˜¯ä¸€è‡´çš„ã€‚



## æ•°æ®åŠ è½½

### å›¾åƒæ•°æ®å˜æ¢

transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])

Normalizeæ˜¯æŠŠå›¾åƒæ•°æ®ä»[0,1]å˜æˆ[-1,1]ï¼Œå˜æ¢å…¬å¼æ˜¯image=(image-mean)/stdï¼Œé‚£ä¹ˆå…¶ä¸­çš„å‚æ•°å°±åˆ†åˆ«æ˜¯ä¸‰ä¸ªé€šé“çš„meanå’Œstdï¼Œè¿™ä¸ªå‡å€¼å’Œæ ‡å‡†å·®éœ€è¦è‡ªå·±è®¡ç®—ï¼ŒèŒƒå›´å°±æ˜¯è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ‰€æœ‰å›¾åƒã€‚

### DataLoader

[CSDNåŸæ–‡é“¾æ¥](https://blog.csdn.net/weixin_42468475/article/details/108714940)
[collate_fnå‚æ•°ä½¿ç”¨è¯¦è§£ â€”â€” çŸ¥ä¹](https://zhuanlan.zhihu.com/p/361830892)
[num_workså‚æ•° â€”â€” CSDN](https://blog.csdn.net/qq_24407657/article/details/103992170)

---

åŠ è½½ä¸€ä¸ªbatchçš„æ•°æ®è¿™ä¸€æ­¥éœ€è¦ä½¿ç”¨ä¸€ä¸ª`torch.utils.data.DataLoader`å¯¹è±¡ï¼Œå¹¶ä¸”DataLoaderæ˜¯ä¸€ä¸ªåŸºäºæŸä¸ªdatasetçš„iterableï¼Œè¿™ä¸ªiterableæ¯æ¬¡ä»datasetä¸­åŸºäºæŸç§é‡‡æ ·åŸåˆ™å–å‡ºä¸€ä¸ªbatchçš„æ•°æ®ã€‚
ä¹Ÿå¯ä»¥è¿™æ ·è¯´ï¼šTorchä¸­å¯ä»¥åˆ›å»ºä¸€ä¸ªtorch.utils.data.==Dataset==å¯¹è±¡ï¼Œå¹¶ä¸torch.utils.data.==DataLoader==ä¸€èµ·ä½¿ç”¨ï¼Œåœ¨è®­ç»ƒæ¨¡å‹æ—¶ä¸æ–­ä¸ºæ¨¡å‹æä¾›æ•°æ®ã€‚

**torch.utils.data.DataLoader**

å®šä¹‰ï¼šData loader. Combines a dataset and a sampler, and provides an iterable over the given dataset.
æ„é€ å‡½æ•°:
```python
torch.utils.data.DataLoader(dataset, 
							batch_size=1, 
							shuffle=False, 
							sampler=None,
							batch_sampler=None, num_workers=0, collate_fn=None,
							pin_memory=False, drop_last=False, timeout=0,
							worker_init_fn=None)
```
- dataset: æŠ½è±¡ç±»,åŒ…å«ä¸¤ç§ç±»å‹
	- `map-style datasets `
	- `iterable-style datasets`
- batch_size : æ¯ä¸€æ¬¡æŠ½æ ·çš„batch-sizeå¤§å°
- shuffle : Trueåˆ™éšæœºæ‰“ä¹±æ•°æ®
- Num_worksï¼šå°†batchåŠ è½½è¿›RAMçš„è¿›ç¨‹æ•°ã€‚å†…å­˜å¼€é”€å¤§ï¼ŒCPUè´Ÿæ‹…å¤§ã€‚å¯èƒ½ä¹‹åå‡ æ¬¡è¿­ä»£çš„æ•°æ®åœ¨æœ¬æ¬¡è¿­ä»£çš„æ—¶å€™å·²ç»åŠ è½½è¿›å†…å­˜ã€‚
- collate_fnï¼šå¦‚ä½•å–æ ·æœ¬çš„ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰è‡ªå·±çš„å‡½æ•°æ¥å‡†ç¡®åœ°å®ç°æƒ³è¦çš„åŠŸèƒ½ã€‚
- drop_lastï¼šå‘Šè¯‰å¦‚ä½•å¤„ç†æ•°æ®é›†é•¿åº¦é™¤äºbatch_sizeä½™ä¸‹çš„æ•°æ®ã€‚Trueå°±æŠ›å¼ƒï¼Œå¦åˆ™ä¿ç•™ã€‚

**Map-style datasets**

æ˜¯ä¸€ä¸ªç±»ï¼Œè¦æ±‚æœ‰ `__getitem__()`and`__len__()`è¿™ä¸¤ä¸ªæ„é€ å‡½æ•°ï¼Œä»£è¡¨ä¸€ä¸ªä»ç´¢å¼•æ˜ å°„åˆ°æ•°æ®æ ·æœ¬ã€‚
- `__getitem__()`: æ ¹æ®ç´¢å¼•indexéå†æ•°æ®
- `__len__()`: è¿”å›æ•°æ®é›†çš„é•¿åº¦
- å¯ç¼–å†™ç‹¬ç«‹çš„æ•°æ®å¤„ç†å‡½æ•°
	- åœ¨ `__getitem()__` å‡½æ•°ä¸­è¿›è¡Œè°ƒç”¨
	- ç›´æ¥å°†æ•°æ®å¤„ç†å‡½æ•°å†™åœ¨ `__getitem()__` æˆ–è€… `__init()__` å‡½æ•°ä¸­ï¼Œä½†æ˜¯`__getitem()__`
	å¿…é¡»æ ¹æ®==index==è¿”å›å“åº”çš„å€¼ï¼Œè¯¥å€¼ä¼šé€šè¿‡indexä¼ åˆ°dataloaderä¸­è¿›è¡Œåç»­çš„batchæ‰¹å¤„ç†ã€‚

åŸºæœ¬éœ€è¦æ»¡è¶³ï¼š
```python
def __getitem__(self, index):
    return self.src[index], self.trg[index]

def __len__(self):
	return len(self.src)  
```



`getitem()`æ–¹æ³•ç”¨æ¥ä»datasetsä¸­è¯»å–ä¸€æ¡æ•°æ®ï¼Œè¿™æ¡æ•°æ®åŒ…å«è®­ç»ƒ**å›¾ç‰‡**ï¼ˆå·²CVè·ç¦»ï¼‰å’Œ**æ ‡ç­¾**ï¼Œå‚æ•°indexè¡¨ç¤ºå›¾ç‰‡å’Œæ ‡ç­¾åœ¨æ€»æ•°æ®é›†ä¸­çš„Indexã€‚

`len()`æ–¹æ³•è¿”å›æ•°æ®é›†çš„æ€»é•¿åº¦ï¼ˆè®­ç»ƒé›†çš„æ€»æ•°ï¼‰ã€‚

**å®ç° MyDatasets ç±»**

1. ç®€å•ç›´ç™½

æŠŠ x å’Œ label åˆ†åˆ«è£…å…¥ä¸¤ä¸ªåˆ—è¡¨ self.src å’Œ self.trg ï¼Œç„¶åé€šè¿‡ getitem(self, idex) è¿”å›å¯¹åº”å…ƒç´ 
```python
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader
 
class My_dataset(Dataset):
    def __init__(self):
        super().__init__()
        ## ä½¿ç”¨sinå‡½æ•°è¿”å›10000ä¸ªæ—¶é—´åºåˆ—,å¦‚æœä¸è‡ªå·±æ„é€ æ•°æ®ï¼Œå°±ä½¿ç”¨numpy,pandasç­‰è¯»å–è‡ªå·±çš„æ•°æ®ä¸ºxå³å¯ã€‚
        ## ä»¥ä¸‹æ•°æ®ç»„ç»‡è¿™å—æ—¢å¯ä»¥æ”¾åœ¨initæ–¹æ³•é‡Œï¼Œä¹Ÿå¯ä»¥æ”¾åœ¨getitemæ–¹æ³•é‡Œ
        self.x = torch.randn(1000,3)
        self.y = self.x.sum(axis=1)
        self.src,  self.trg = [], []
        for i in range(1000):
            self.src.append(self.x[i])
            self.trg.append(self.y[i])
    
           
    def __getitem__(self, index):
        return self.src[index], self.trg[index]

    def __len__(self):
        return len(self.src) 
        
 ## æˆ–è€…return len(self.trg), srcå’Œtrgé•¿åº¦ä¸€æ ·
 
data_train = My_dataset()
data_test = My_dataset()
data_loader_train = DataLoader(data_train, batch_size=5, shuffle=False)
data_loader_test = DataLoader(data_test, batch_size=5, shuffle=False)
## i_batchçš„å¤šå°‘æ ¹æ®batch sizeå’Œdef __len__(self)è¿”å›çš„é•¿åº¦ç¡®å®š
## batch_dataè¿”å›çš„å€¼æ ¹æ®def __getitem__(self, index)æ¥ç¡®å®š
## å¯¹è®­ç»ƒé›†ï¼š(ä¸å¤ªæ¸…æ¥šenumerateè¿”å›ä»€ä¹ˆçš„æ—¶å€™å°±å¤šprintè¯•è¯•)
for i_batch, batch_data in enumerate(data_loader_train):
    print(i_batch)  ## æ‰“å°batchç¼–å·
    print(batch_data[0])  ## æ‰“å°è¯¥batché‡Œé¢src
    print(batch_data[1])  ## æ‰“å°è¯¥batché‡Œé¢trg
## å¯¹æµ‹è¯•é›†ï¼šï¼ˆä¸‹é¢çš„è¯­å¥ä¹Ÿå¯ä»¥ï¼‰
for i_batch, (src, trg) in enumerate(data_loader_test):
    print(i_batch)  ## æ‰“å°batchç¼–å·
    print(src)  ## æ‰“å°è¯¥batché‡Œé¢srcçš„å°ºå¯¸
    print(trg)  ## æ‰“å°è¯¥batché‡Œé¢trgçš„å°ºå¯¸    
```

ç”Ÿæˆçš„data_trainå¯ä»¥é€šè¿‡ `data_train[xxx]`ç›´æ¥ç´¢å¼•æŸä¸ªå…ƒç´ ï¼Œæˆ–è€…é€šè¿‡`next(iter(data_train))` å¾—åˆ°ä¸€æ¡æ¡çš„æ•°æ®ã€‚

2. å€ŸåŠ©TensorDatasetå°†æ•°æ®åŒ…è£…æˆdataset

```python
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader, TensorDataset
 
src = torch.sin(torch.arange(1, 1000, 0.1))
trg = torch.cos(torch.arange(1, 1000, 0.1))
 
data = TensorDataset(src, trg)
data_loader = DataLoader(data, batch_size=5, shuffle=False)
for i_batch, batch_data in enumerate(data_loader):
    print(i_batch)  ## æ‰“å°batchç¼–å·
    print(batch_data[0].size())  ## æ‰“å°è¯¥batché‡Œé¢src
    print(batch_data[1].size())  ## æ‰“å°è¯¥batché‡Œé¢trg
```

3. åœ°å€è¯»å–ï¼Œç”Ÿæˆæ•°æ®çš„è·¯å¾„ txtæ–‡ä»¶

```python
import os

from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import matplotlib.image as mpimg



## å¯¹æ‰€æœ‰å›¾ç‰‡ç”Ÿæˆpath-label map.txt è¿™ä¸ªç¨‹åºå¯æ ¹æ®å®é™…éœ€è¦é€‚å½“ä¿®æ”¹
def generate_map(root_dir):
	##å¾—åˆ°å½“å‰ç»å¯¹è·¯å¾„
    current_path = os.path.abspath('.')
    ##os.path.dirname()å‘å‰é€€ä¸€ä¸ªè·¯å¾„
    father_path = os.path.abspath(os.path.dirname(current_path) + os.path.sep + ".")

    with open(root_dir + 'map.txt', 'w') as wfp:
        for idx in range(10):
            subdir = os.path.join(root_dir, '%d/' % idx)
            for file_name in os.listdir(subdir):
                abs_name = os.path.join(father_path, subdir, file_name)
                ## linux_abs_name = abs_name.replace("\\", '/')
                wfp.write('{file_dir} {label}\n'.format(file_dir=linux_abs_name, label=idx))

## å®ç°MyDatasetsç±»
class MyDatasets(Dataset):

    def __init__(self, dir):
        ## è·å–æ•°æ®å­˜æ”¾çš„dir
        ## ä¾‹å¦‚d:/images/
        self.data_dir = dir
        ## ç”¨äºå­˜æ”¾(image,label) tupleçš„list,å­˜æ”¾çš„æ•°æ®ä¾‹å¦‚(d:/image/1.png,4)
        self.image_target_list = []
        ## ä»dir--labelçš„mapæ–‡ä»¶ä¸­å°†æ‰€æœ‰çš„tupleå¯¹è¯»å–åˆ°image_target_listä¸­
        ## map.txtä¸­å…¨éƒ¨å­˜æ”¾çš„æ˜¯d:/.../image_data/1/3.jpg 1 è·¯å¾„æœ€å¥½æ˜¯ç»å¯¹è·¯å¾„
        with open(os.path.join(dir, 'map.txt'), 'r') as fp:
            content = fp.readlines()
            ##s.rstrip()åˆ é™¤å­—ç¬¦ä¸²æœ«å°¾æŒ‡å®šå­—ç¬¦ï¼ˆé»˜è®¤æ˜¯å­—ç¬¦ï¼‰
            ## å¾—åˆ° [['d:/.../image_data/1/3.jpg', '1'], ...,]
            str_list = [s.rstrip().split() for s in content]
            ## å°†æ‰€æœ‰å›¾ç‰‡çš„dir--labelå¯¹éƒ½æ”¾å…¥åˆ—è¡¨ï¼Œå¦‚æœè¦æ‰§è¡Œå¤šä¸ªepochï¼Œå¯ä»¥åœ¨è¿™é‡Œå¤šå¤åˆ¶å‡ éï¼Œç„¶åç»Ÿä¸€shuffleæ¯”è¾ƒå¥½
            self.image_target_list = [(x[0], int(x[1])) for x in str_list]

    def __getitem__(self, index):
        image_label_pair = self.image_target_list[index]
        ## æŒ‰pathè¯»å–å›¾ç‰‡æ•°æ®ï¼Œå¹¶è½¬æ¢ä¸ºå›¾ç‰‡æ ¼å¼ä¾‹å¦‚[3,32,32]
        ## å¯ä»¥ç”¨åˆ«çš„ä»£æ›¿
        img = mpimg.imread(image_label_pair[0])
        return img, image_label_pair[1]

    def __len__(self):
        return len(self.image_target_list)


if __name__ == '__main__':
    ## ç”Ÿæˆmap.txt
    ## generate_map('train/')

    train_loader = DataLoader(MyDatasets('train/'), batch_size=128, shuffle=True)

    for step in range(20000):
        for idx, (img, label) in enumerate(train_loader):
            print(img.shape)
            print(label.shape)
```

## ç½‘ç»œæ¨¡å‹

### apply åˆå§‹åŒ–å‚æ•°
[pytorchç³»åˆ—10 --- å¦‚ä½•è‡ªå®šä¹‰å‚æ•°åˆå§‹åŒ–æ–¹å¼ ï¼Œapply()](https://blog.csdn.net/dss_dssssd/article/details/83990511)



### nn.Conv2d
[Pytorchçš„nn.Conv2dï¼ˆï¼‰è¯¦è§£_é£é›ªå¤œå½’äººoçš„åšå®¢-CSDNåšå®¢_nnæ˜¯ä»€ä¹ˆæ„æ€](https://blog.csdn.net/qq_42079689/article/details/102642610)

---

```python
class Net(nn.Module):
    def __init__(self):
        nn.Module.__init__(self)
        self.conv2d = nn.Conv2d(in_channels=3,out_channels=64,kernel_size=4,stride=2,padding=1)

    def forward(self, x):
        print(x.requires_grad)
        x = self.conv2d(x)
        return x
    
print(net.conv2d.weight)
print(net.conv2d.bias)
```


### flatten
[CNNçš„Flattenæ“ä½œ](https://cloud.tencent.com/developer/article/1620842)

---


- `torch.flatten(Python function, in torch)`
- `torch.nn.Flatten(Python class, in torch.nn)`
- `torch.Tensor.flatten(Python methodm in torch.nn.Tensor)`

#### torch.flatten
```python
#å±•å¹³ä¸€ä¸ªè¿ç»­èŒƒå›´çš„ç»´åº¦ï¼Œè¾“å‡ºç±»å‹ä¸ºTensor
torch.flatten(input, start_dim=0, end_dim=-1) â†’ Tensor
# Parametersï¼šinput (Tensor) â€“ è¾“å…¥ä¸ºTensor
# start_dim (int) â€“ å±•å¹³çš„å¼€å§‹ç»´åº¦
# end_dim (int) â€“ å±•å¹³çš„æœ€åç»´åº¦

#example
#ä¸€ä¸ª3x2x2çš„ä¸‰ç»´å¼ é‡
>>> t = torch.tensor([[[1, 2], [3, 4]],
                      [[5, 6], [7, 8]],
	                  [[9, 10],[11, 12]]])
#å½“å¼€å§‹ç»´åº¦ä¸º0ï¼Œæœ€åç»´åº¦ä¸º-1ï¼Œå±•å¼€ä¸ºä¸€ç»´
>>> torch.flatten(t)
tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])
#å½“å¼€å§‹ç»´åº¦ä¸º0ï¼Œæœ€åç»´åº¦ä¸º-1ï¼Œå±•å¼€ä¸º3x4ï¼Œä¹Ÿå°±æ˜¯è¯´ç¬¬ä¸€ç»´åº¦ä¸å˜ï¼Œåé¢çš„å‹ç¼©
>>> torch.flatten(t, start_dim=1)
tensor([[ 1,  2,  3,  4],
        [ 5,  6,  7,  8],
        [ 9, 10, 11, 12]])
>>> torch.flatten(t, start_dim=1).size()
torch.Size([3, 4])
#ä¸‹é¢çš„å’Œä¸Šé¢è¿›è¡Œå¯¹æ¯”åº”è¯¥å°±èƒ½çœ‹å‡ºæ˜¯ï¼Œå½“é”å®šæœ€åçš„ç»´åº¦çš„æ—¶å€™
#å‰é¢çš„å°±ä¼šåˆå¹¶
>>> torch.flatten(t, start_dim=0, end_dim=1)
tensor([[ 1,  2],
        [ 3,  4],
        [ 5,  6],
        [ 7,  8],
        [ 9, 10],
        [11, 12]])
>>> torch.flatten(t, start_dim=0, end_dim=1).size()
torch.Size([6, 2])

```


#### torch.nn.Flatten()
torch.nn.Flatten()å¯ä»¥æ˜¯Sequentialæ¨¡å‹çš„ä¸€å±‚

pytorchä¸­çš„ torch.nn.Flatten ç±»å’Œ torch.Tensor.flatten æ–¹æ³•å…¶å®éƒ½æ˜¯åŸºäº torch.flatten å‡½æ•°å®ç°çš„ã€‚


### nn.Sequential
[pytorchç³»åˆ—7 -----nn.Sequentialè®²è§£](https://blog.csdn.net/dss_dssssd/article/details/82980222)

---
nn.Sequential
A sequential container. Modules will be added to it in the order they are passed in the constructor. Alternatively, an ordered dict of modules can also be passed in.

ä¸€ä¸ªæœ‰åºçš„==å®¹å™¨==ï¼Œç¥ç»ç½‘ç»œæ¨¡å—å°†æŒ‰ç…§åœ¨ä¼ å…¥æ„é€ å™¨çš„é¡ºåºä¾æ¬¡è¢«æ·»åŠ åˆ°è®¡ç®—å›¾ä¸­æ‰§è¡Œï¼ŒåŒæ—¶ä»¥ç¥ç»ç½‘ç»œæ¨¡å—ä¸ºå…ƒç´ çš„æœ‰åºå­—å…¸ä¹Ÿå¯ä»¥ä½œä¸ºä¼ å…¥å‚æ•°ã€‚

```python
# Example of using Sequential
model = nn.Sequential(
		  nn.Conv2d(1,20,5),
		  nn.ReLU(),
		  nn.Conv2d(20,64,5),
		  nn.ReLU()
		)

# Example of using Sequential with OrderedDict
model = nn.Sequential(OrderedDict([
		  ('conv1', nn.Conv2d(1,20,5)),
		  ('relu1', nn.ReLU()),
		  ('conv2', nn.Conv2d(20,64,5)),
		  ('relu2', nn.ReLU())
		]))

```



## ç½‘ç»œè®­ç»ƒ

### with torch.no_grad()

> å‚è€ƒï¼šhttps://blog.csdn.net/sazass/article/details/116668755

ä½œç”¨ï¼šåœ¨è¯¥æ¨¡å—ä¸‹ï¼Œæ‰€æœ‰è®¡ç®—å¾—å‡ºçš„tensorçš„requires_gradéƒ½è‡ªåŠ¨è®¾ç½®ä¸ºFalseã€‚å½“requires_gradè®¾ç½®ä¸ºFalseæ—¶,åå‘ä¼ æ’­æ—¶å°±ä¸ä¼šè‡ªåŠ¨æ±‚å¯¼äº†ï¼Œå› æ­¤å¤§å¤§èŠ‚çº¦äº†æ˜¾å­˜æˆ–è€…è¯´å†…å­˜ã€‚



### nn.DataParallel
[Pytorchçš„nn.DataParallel - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/102697821)
å¤šå¡å¹¶è¡Œçš„å‘½ä»¤ï¼Œä»¥åŠå¯èƒ½å‡ºçš„é”™è¯¯

---

å½“è¿­ä»£æ¬¡æ•°æˆ–è€…epochè¶³å¤Ÿå¤§çš„æ—¶å€™ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šä½¿ç”¨nn.DataParallelå‡½æ•°æ¥ç”¨å¤šä¸ªGPUæ¥åŠ é€Ÿè®­ç»ƒ

````python
CLASS torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)
````

moduleå³è¡¨ç¤ºä½ å®šä¹‰çš„æ¨¡å‹
device_idsè¡¨ç¤ºä½ è®­ç»ƒçš„device
output_deviceè¿™ä¸ªå‚æ•°è¡¨ç¤ºè¾“å‡ºç»“æœçš„device


### nn.Parameter()
[PyTorchä¸­çš„torch.nn.Parameter() è¯¦è§£_Adenialzzçš„åšå®¢-CSDNåšå®¢](https://blog.csdn.net/weixin_44966641/article/details/118730730)

---

é¦–å…ˆå¯ä»¥æŠŠè¿™ä¸ªå‡½æ•°ç†è§£ä¸ºç±»å‹è½¬æ¢å‡½æ•°ï¼Œå°†ä¸€ä¸ªä¸å¯è®­ç»ƒçš„ç±»å‹Tensorè½¬æ¢æˆå¯ä»¥è®­ç»ƒçš„ç±»å‹parameterå¹¶å°†è¿™ä¸ªparameterç»‘å®šåˆ°è¿™ä¸ªmoduleé‡Œé¢(net.parameter()ä¸­å°±æœ‰è¿™ä¸ªç»‘å®šçš„parameterï¼Œæ‰€ä»¥åœ¨å‚æ•°ä¼˜åŒ–çš„æ—¶å€™å¯ä»¥è¿›è¡Œä¼˜åŒ–çš„)ï¼Œæ‰€ä»¥ç»è¿‡ç±»å‹è½¬æ¢è¿™ä¸ªself.vå˜æˆäº†æ¨¡å‹çš„ä¸€éƒ¨åˆ†ï¼Œæˆä¸ºäº†æ¨¡å‹ä¸­æ ¹æ®è®­ç»ƒå¯ä»¥æ”¹åŠ¨çš„å‚æ•°äº†ã€‚ä½¿ç”¨è¿™ä¸ªå‡½æ•°çš„ç›®çš„ä¹Ÿæ˜¯æƒ³è®©æŸäº›å˜é‡åœ¨å­¦ä¹ çš„è¿‡ç¨‹ä¸­ä¸æ–­çš„ä¿®æ”¹å…¶å€¼ä»¥è¾¾åˆ°æœ€ä¼˜åŒ–ã€‚

```python
self.pos_embedding = nn.Parameter(torch.randn(1, num_patches+1, dim))
self.cls_token = nn.Parameter(torch.randn(1, 1, dim))
```






## åŠŸèƒ½å‡½æ•°

### ç”Ÿæˆå¼ é‡
`torch.rand(x,y)` ç”Ÿæˆxè¡Œyåˆ—çš„å‡åŒ€åˆ†å¸ƒçš„å¼ é‡
`torch.randn(x,y)` ç”Ÿæˆxè¡Œyåˆ—çš„æ­£æ€åˆ†å¸ƒçš„å¼ é‡

```python
A = torch.tensor([1.0,1.0],[2,2]) 
A 
#tensor([1.,1.], 
#       [2.,2.])  
```


### nn.functional.interpolate()

`torch.nn.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None, recompute_scale_factor=None)`

åŠŸèƒ½ï¼šåˆ©ç”¨æ’å€¼æ–¹æ³•ï¼Œå¯¹è¾“å…¥çš„å¼ é‡æ•°ç»„è¿›è¡Œä¸Š\ä¸‹**é‡‡æ ·**æ“ä½œï¼Œæ¢å¥è¯è¯´å°±æ˜¯ç§‘å­¦åˆç†åœ°æ”¹å˜æ•°ç»„çš„å°ºå¯¸å¤§å°ï¼Œå°½é‡ä¿æŒæ•°æ®å®Œæ•´ã€‚

`input(Tensor)`ï¼šéœ€è¦è¿›è¡Œé‡‡æ ·å¤„ç†çš„æ•°ç»„ã€‚
`size(intæˆ–åºåˆ—)`ï¼šè¾“å‡ºç©ºé—´çš„å¤§å°
`scale_factor(floatæˆ–åºåˆ—)`ï¼šç©ºé—´å¤§å°çš„ä¹˜æ•°
`mode(str)`ï¼šç”¨äºé‡‡æ ·çš„ç®—æ³•ã€‚'nearest'| 'linear'| 'bilinear'| 'bicubic'| 'trilinear'| 'area'ã€‚é»˜è®¤ï¼š'nearest'
`align_corners(bool)`ï¼šåœ¨å‡ ä½•ä¸Šï¼Œæˆ‘ä»¬å°†è¾“å…¥å’Œè¾“å‡ºçš„åƒç´ è§†ä¸ºæ­£æ–¹å½¢è€Œä¸æ˜¯ç‚¹ã€‚å¦‚æœè®¾ç½®ä¸ºTrueï¼Œåˆ™è¾“å…¥å’Œè¾“å‡ºå¼ é‡æŒ‰å…¶è§’åƒç´ çš„ä¸­å¿ƒç‚¹å¯¹é½ï¼Œä¿ç•™è§’åƒç´ å¤„çš„å€¼ã€‚å¦‚æœè®¾ç½®ä¸ºFalseï¼Œåˆ™è¾“å…¥å’Œè¾“å‡ºå¼ é‡é€šè¿‡å…¶è§’åƒç´ çš„è§’ç‚¹å¯¹é½ï¼Œå¹¶ä¸”æ’å€¼ä½¿ç”¨è¾¹ç¼˜å€¼å¡«å……ç”¨äºè¾¹ç•Œå¤–å€¼ï¼Œä½¿æ­¤æ“ä½œåœ¨ä¿æŒä¸å˜æ—¶ç‹¬ç«‹äºè¾“å…¥å¤§å°scale_factorã€‚
`recompute_scale_facto(bool)`ï¼šé‡æ–°è®¡ç®—ç”¨äºæ’å€¼è®¡ç®—çš„ scale_factorã€‚å½“scale_factorä½œä¸ºå‚æ•°ä¼ é€’æ—¶ï¼Œå®ƒç”¨äºè®¡ç®—output_sizeã€‚å¦‚æœrecompute_scale_factorçš„Falseæˆ–æ²¡æœ‰æŒ‡å®šï¼Œä¼ å…¥çš„scale_factorå°†åœ¨æ’å€¼è®¡ç®—ä¸­ä½¿ç”¨ã€‚å¦åˆ™ï¼Œå°†æ ¹æ®ç”¨äºæ’å€¼è®¡ç®—çš„è¾“å‡ºå’Œè¾“å…¥å¤§å°è®¡ç®—æ–°çš„scale_factorï¼ˆå³ï¼Œå¦‚æœè®¡ç®—çš„output_sizeæ˜¾å¼ä¼ å…¥ï¼Œåˆ™è®¡ç®—å°†ç›¸åŒ ï¼‰ã€‚æ³¨æ„å½“scale_factor æ˜¯æµ®ç‚¹æ•°ï¼Œç”±äºèˆå…¥å’Œç²¾åº¦é—®é¢˜ï¼Œé‡æ–°è®¡ç®—çš„ scale_factor å¯èƒ½ä¸ä¼ å…¥çš„ä¸åŒã€‚




æ³¨æ„ï¼š

- è¾“å…¥çš„å¼ é‡æ•°ç»„é‡Œé¢çš„æ•°æ®ç±»å‹å¿…é¡»æ˜¯floatã€‚
- è¾“å…¥çš„æ•°ç»„ç»´æ•°åªèƒ½æ˜¯3ã€4æˆ–5ï¼Œåˆ†åˆ«å¯¹åº”äºæ—¶é—´ã€ç©ºé—´ã€ä½“ç§¯é‡‡æ ·ã€‚
- ä¸å¯¹è¾“å…¥æ•°ç»„çš„å‰ä¸¤ä¸ªç»´åº¦(æ‰¹æ¬¡å’Œé€šé“)é‡‡æ ·ï¼Œä»ç¬¬ä¸‰ä¸ªç»´åº¦å¾€åå¼€å§‹é‡‡æ ·å¤„ç†ã€‚
- è¾“å…¥çš„ç»´åº¦å½¢å¼ä¸ºï¼šæ‰¹é‡(batch_size)Ã—é€šé“(channel)Ã—[å¯é€‰æ·±åº¦]Ã—[å¯é€‰é«˜åº¦]Ã—å®½åº¦(å‰ä¸¤ä¸ªç»´åº¦å…·æœ‰ç‰¹æ®Šçš„å«ä¹‰ï¼Œä¸è¿›è¡Œé‡‡æ ·å¤„ç†)
- sizeä¸scale_factorä¸¤ä¸ªå‚æ•°åªèƒ½å®šä¹‰ä¸€ä¸ªï¼Œå³ä¸¤ç§é‡‡æ ·æ¨¡å¼åªèƒ½ç”¨ä¸€ä¸ªã€‚è¦ä¹ˆè®©æ•°ç»„æ”¾å¤§æˆç‰¹å®šå¤§å°ã€è¦ä¹ˆç»™å®šç‰¹å®šç³»æ•°ï¼Œæ¥ç­‰æ¯”æ”¾å¤§æ•°ç»„ã€‚
- å¦‚æœsizeæˆ–è€…scale_factorè¾“å…¥åºåˆ—ï¼Œåˆ™å¿…é¡»åŒ¹é…è¾“å…¥çš„å¤§å°ã€‚å¦‚æœè¾“å…¥å››ç»´ï¼Œåˆ™å®ƒä»¬çš„åºåˆ—é•¿åº¦å¿…é¡»æ˜¯2ï¼Œå¦‚æœè¾“å…¥æ˜¯äº”ç»´ï¼Œåˆ™å®ƒä»¬çš„åºåˆ—é•¿åº¦å¿…é¡»æ˜¯3ã€‚
- å¦‚æœsizeè¾“å…¥æ•´æ•°xï¼Œåˆ™ç›¸å½“äºæŠŠ3ã€4ç»´åº¦æ”¾å¤§æˆ(x,x)å¤§å°(è¾“å…¥ä»¥å››ç»´ä¸ºä¾‹ï¼Œä¸‹é¢åŒç†)ã€‚
- å¦‚æœscale_factorè¾“å…¥æ•´æ•°xï¼Œåˆ™ç›¸å½“äºæŠŠ3ã€4ç»´åº¦éƒ½ç­‰æ¯”æ”¾å¤§xå€ã€‚
- modeæ˜¯â€™linearâ€™æ—¶è¾“å…¥å¿…é¡»æ˜¯3ç»´çš„ï¼›æ˜¯â€™bicubicâ€™æ—¶è¾“å…¥å¿…é¡»æ˜¯4ç»´çš„ï¼›æ˜¯â€™trilinearâ€™æ—¶è¾“å…¥å¿…é¡»æ˜¯5ç»´çš„
- å¦‚æœalign_cornersè¢«èµ‹å€¼ï¼Œåˆ™modeå¿…é¡»æ˜¯'linear'ï¼Œ'bilinear'ï¼Œ'bicubic'æˆ–'trilinear'ä¸­çš„ä¸€ä¸ªã€‚
- æ’å€¼æ–¹æ³•ä¸åŒï¼Œç»“æœå°±ä¸ä¸€æ ·ï¼Œéœ€è¦ç»“åˆå…·ä½“ä»»åŠ¡ï¼Œé€‰æ‹©åˆé€‚çš„æ’å€¼æ–¹æ³•ã€‚

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºCSDNåšä¸»ã€Œè§†è§‰èŒæ–°ã€ã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚
åŸæ–‡é“¾æ¥ï¼šhttps://blog.csdn.net/qq_50001789/article/details/120297401

### torch.max()

`torch.max(input) â†’ Tensor`:è¿”å›è¾“å…¥tensorä¸­æ‰€æœ‰å…ƒç´ çš„æœ€å¤§å€¼

`torch.max(input, dim, keepdim=False, out=None) -> (Tensor, LongTensor)`: æŒ‰ç»´åº¦dim è¿”å›æœ€å¤§å€¼ï¼Œå¹¶ä¸”è¿”å›ç´¢å¼•ã€‚

```python
torch.max()[0]ï¼Œ åªè¿”å›æœ€å¤§å€¼çš„æ¯ä¸ªæ•°

troch.max()[1]ï¼Œ åªè¿”å›æœ€å¤§å€¼çš„æ¯ä¸ªç´¢å¼•

torch.max()[1].data åªè¿”å›variableä¸­çš„æ•°æ®éƒ¨åˆ†ï¼ˆå»æ‰Variable containing:ï¼‰

torch.max()[1].data.numpy() æŠŠæ•°æ®è½¬åŒ–æˆnumpy ndarry

torch.max()[1].data.numpy().squeeze() æŠŠæ•°æ®æ¡ç›®ä¸­ç»´åº¦ä¸º1 çš„åˆ é™¤æ‰
```


### nn.init.normal_
`torch.nn.init.normal(tensor, mean=0, std=1)`
ä»ç»™å®šå‡å€¼å’Œæ ‡å‡†å·®çš„æ­£æ€åˆ†å¸ƒN(mean, std)ä¸­ç”Ÿæˆå€¼ï¼Œå¡«å……è¾“å…¥çš„å¼ é‡æˆ–å˜é‡





# python

### å­—å…¸
#### ç§»é™¤ key-value å¯¹
```python
dic = {
	'a': 1,
	'b': 2,
	'c': 3
}

# del
del dic['a']

# pop()
dic.pop('a')

# items()
new_dic = {key:val for key, val in dic.items() if key != 'a'}
```

### args & kwargs

https://zhuanlan.zhihu.com/p/50804195

args æ˜¯ arguments çš„ç¼©å†™ï¼Œè¡¨ç¤ºä½ç½®å‚æ•°ï¼›
kwargs æ˜¯ keyword arguments çš„ç¼©å†™ï¼Œè¡¨ç¤ºå…³é”®å­—å‚æ•°ã€‚

` *args` å¿…é¡»æ”¾åœ¨ `**kwargs` çš„å‰é¢ï¼Œå› ä¸ºä½ç½®å‚æ•°åœ¨å…³é”®å­—å‚æ•°çš„å‰é¢

`*args`å°±æ˜¯å°±æ˜¯ä¼ é€’ä¸€ä¸ªå¯å˜å‚æ•°**å…ƒç»„**ç»™å‡½æ•°å®å‚

`**kwargs`åˆ™æ˜¯å°†ä¸€ä¸ªå¯å˜çš„å…³é”®å­—å‚æ•°çš„**å­—å…¸**ä¼ ç»™å‡½æ•°å®å‚



### Str

`str.lower()` å…¨éƒ¨è½¬åŒ–ä¸ºå°å†™å­—æ¯



### setattr() & getattr()

`setattr()`: è®¾ç½®å±æ€§å€¼ï¼Œè¯¥å±æ€§ä¸ä¸€å®šæ˜¯å­˜åœ¨çš„ã€‚

```python
setattr(object, name, value)
object -- å¯¹è±¡ã€‚
name -- å­—ç¬¦ä¸²ï¼Œå¯¹è±¡å±æ€§ã€‚
value -- å±æ€§å€¼ã€‚
```

```python
å¯¹å·²å­˜åœ¨çš„å±æ€§è¿›è¡Œèµ‹å€¼ï¼š
>>>class A(object):
    bar = 1

>>> a = A()
>>> getattr(a, 'bar')          # è·å–å±æ€§ bar å€¼
1
>>> setattr(a, 'bar', 5)       # è®¾ç½®å±æ€§ bar å€¼
>>> a.bar
5
```

```python
å¦‚æœå±æ€§ä¸å­˜åœ¨ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„å¯¹è±¡å±æ€§ï¼Œå¹¶å¯¹å±æ€§èµ‹å€¼ï¼š
class A():
    name = "runoob"
... 
>>> a = A()
>>> setattr(a, "age", 28)
>>> print(a.age)
28
>>>
```


### å¤„ç†json

#### å•ä¸ªjsonå¯¹è±¡
```python
import json
with open('superheroes.json') as f:
    superHeroSquad = json.load(f)
print(type(superHeroSquad))  # Output: dict
print(superHeroSquad.keys())
# Output: dict_keys(['squadName', 'homeTown', 'formed', 'secretBase', 'active', 'members'])
```

- å‡½æ•°load()ä½œç”¨ä¸ºè¯»å–JSONæ–‡ä»¶ç”ŸæˆPythonå¯¹è±¡
- å‡½æ•°loads()ä½œç”¨ä¸ºè¯»å–JSON å­—ç¬¦ä¸²æµç”ŸæˆPythonå¯¹è±¡

å­—å…¸

```python
import json

with open("save.json","r", encoding='utf-8'  ) as f:
    load_dict = json.load(f)

print(load_dict)

```

```python
import json

dict1 = {"å°æ˜":4,"å¼ ä¸‰":5,"æå››":99}

with open("save.json","w", encoding='utf-8') as f: ## è®¾ç½®'utf-8'ç¼–ç 
    f.write(json.dumps(dict1, ensure_ascii=False, indent=4))  # indent ç¼©è¿›
    ## å¦‚æœensure_ascii=Trueåˆ™ä¼šè¾“å‡ºä¸­æ–‡çš„asciiç ï¼Œè¿™é‡Œè®¾ä¸ºFalse
```


#### å¤šjsonå¯¹è±¡æ–‡ä»¶è¯»å†™

å†™
```python
import json 

def write_jsonlines(json_file_name,date_dict):
    with open(json_file_name, 'a') as f:
        json.dump(date_dict, f)
        f.write("\n")
```

è¯»
```python
import jsonlines

def json_data_read(json_file_name):
    """è¾“å…¥:éœ€è¦è¯»å–çš„å¤šå¯¹è±¡jsonæ–‡ä»¶è·¯å¾„
    è¿”å›:ç”±å¤šä¸ªå­—å…¸ç»„æˆçš„åˆ—è¡¨"""

    json_list = []
    with open(json_file_name, 'r+') as f:
        for item in jsonlines.Reader(f):
            json_list.append(item)

    return  json_list
```

